[{"content":"Install CentOS 搜索并查看一下 CentOS 的 image docker search centos 使用 pull 把 image 拉下来 docker pull centos 运行并进入容器 这里把宿主机的 22222 端口和 CentOS 的 22 端口进行映射，使用 --privileged=true 给予足够的权限，否则打开 SSH 时可能提示权限不够 docker run -tid -p 22222:22 centos --privileged=true centos /sbin/init docker exec -it centos /bin/bash Init CentOS 进入容器之后，我们需要把 SSH 打开，方便宿主机连接\n首先更新下 yum 的 source，如果 CentOS 版本太高的话，不更新安装不上，下面两个命令执行一下就好 sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-* sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-* 安装 SSH Server yum -y install openssh-server 打开 SSH Server sudo service sshd start 如果不存在 service 的话， 把 initscripts 安装一下再执行上面的命令：yum -y install initscripts\n修改密码 # 安装 passwd yum install passwd -y # 执行 passwd 然后输入你的密码 passwd 到这里 SSH 基本就算完成了，可以使用 netstat 查看 22 端口是否打开\n# 如果 netstat 不存在的话先安装 net-tools yum install net-tools # 查看端口 netstat -ntlp 我的执行结果是：\nActive Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 52/sshd tcp6 0 0 :::22 :::* LISTEN 52/sshd 可以看到 22 端口已经被打开\n输入 exit 退出 CentOS，回到宿主机，输入以下命令和密码便能进入到 CentOS\nssh root@127.0.0.1 -p 22222 开发环境搭建 开发环境搭建非常简单，在 Goland 中把 SSH 配置好，并设置为 Linux + amd64 即可。\n相应地， VSCode 也有 SSH 插件，最终把 elf 拿到 CentOS 上 run 就行了，开发全在本地。\n","date":"2022-11-08T00:00:00Z","image":"https://yanghaoyu.xyz/assets/img/hero/imitate-docker.drawio.png","permalink":"https://yanghaoyu.xyz/b/porrima/build-env/","title":"「手写 Docker」 0. 搭建 Linux + Golang 环境"},{"content":" Introduction 在 Linux 中每一个进程都有自己所属的 Namespace，默认所有进程都运行在 root Namespace 下，共享全局资源。\n同时 Linux 大致提供了以下几种 Namespace 功能帮助我们进行资源隔离。\nNamespace Flag Usage Mount Namespace CLONE_NEWNS 隔离各个进程看到的挂载点视图 User Namespace CLONE_NEWUSER 隔离用户 PID Namespace CLONE_NEWPID 隔离 PID IPC Namespace CLONE_NEWIPC 隔离进程间通信，System V IPC 和 POSIX MQ Network Namespace CLONE_NEWNET 隔离网络 UTS Namespace CLONE_NEWUTS 隔离 nodename 和 domainname 相关的 System Call clone() 创建新进程，可以指定新进程的 Namespace int clone(int (*fn)(void* arg), void* child_stack, int flags, void* arg, ...); unshare() 把某个进程移出指定的 Namespace int unshare(int flags); setns() 把某个进程放入指定的 Namespace int setns(int fd, int nstype); UTS Namespace UTS Namespace 主要用来隔离 nodename 和 domainname。 在 Golang 中可以通过指定 cmd.SysProcAttr 来设置 Namespace\nfunc main() { var cmd = exec.Command(\u0026#34;sh\u0026#34;) cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 验证 hostname 被隔离 在进程中：\n$ echo $$ 93 $ readlink /proc/93/ns/uts uts:[4026532307] 在外部的 Terminal 中， 同样执行上述代码可以发现两个线程的 UTS Namespace 是不一样的，这就表明我们的程序被隔离开了， 因此我们在进程内修改 hostname 那么也不会影响到其他的进程的 hostname。\n我的代码如下：\nmain: # main $ hostname # 先查看一下 hostname bfcbd31e5fb7 $ hostname -b howieyoung # 修改 hostname $ hostname # 再次查看 hostname，确保已经修改 howieyoung linux terminal: # linux terminal $ hostname # 在 main 进程修改 hostname 之前查看一下 bfcbd31e5fb7 $ hostname # 在 main 进程修改 hostname 之后查看一下 bfcbd31e5fb7 两次 hostname 是一样的，这也能验证 main 线程被隔离了\n同时可以看到我们执行 echo $$ 获取到的当前进程的 ID 是 93，这似乎有些不正确， 我们期望在容器内把 main 线程看作根结点。这是因为 UTS Namespace 并不会把 PID 隔离开。为了完成这件事，我们需要使用 PID Namespace。\nPID Namespace 我们添加上 PID Namespace，再次运行。\nfunc main() { var cmd = exec.Command(\u0026#34;sh\u0026#34;) cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 验证 PID 被隔离 执行 echo $$\n$ echo $$ 1 当前进程的 id 变成了 1，表明 pid 已经隔离\nIPC Namespace IPC，进程间通信，主要包括 Pipe Socket Semaphore MQ Signal mmap 等。\n在 Linux 中，主要有两套接口 System V 和 POSIX 实现 IPC\nSystem V IPC: 来自于 Unix，最初由 AT\u0026amp;T 开发，1983 年第一次发布 POSIX: IEEE 制定的一组接口，兼容了绝大部分 System V，移植性好 IPC Namespace 用来隔离 System V IPC 和 POSIX message queues。\n每一个 IPC Namespace 都有自己的 System V IPC 和 POSIX message queue。\nfunc main() { var cmd = exec.Command(\u0026#34;sh\u0026#34;) cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 验证 IPC 被隔离 首先在 main 进程下和 linux terminal 内分别运行 ipcs -a 查看 ipc 情况\nmain： # main $ ipcs -a ------ Message Queues -------- key msqid owner perms used-bytes messages ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status ------ Semaphore Arrays -------- key semid owner perms nsems linux terminal # linux terminal $ ipcs -a ------ Message Queues -------- key msqid owner perms used-bytes messages ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status ------ Semaphore Arrays -------- key semid owner perms nsems 可以看到都没有任何的 IPC\n在 main 进程下执行 ipcmk -Q 创建一个 mq，然后查看\n# main $ ipcmk -Q Message queue id: 0 $ ipcs -a # 查看 ipc 情况 ------ Message Queues -------- key msqid owner perms used-bytes messages 0xab342dbe 0 root 644 0 0 # 成功创建 ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status ------ Semaphore Arrays -------- key semid owner perms nsems 打开 terminal，执行 ipcs -a 可以发现在 root Namespace 中是不存在这个 MQ 的， 这就表示我们使用 IPC Namespace 成功地把两个进程的通信资源隔离开了\n# linux terminal $ ipcs -a ------ Message Queues -------- key msqid owner perms used-bytes messages ------ Shared Memory Segments -------- key shmid owner perms bytes nattch status ------ Semaphore Arrays -------- key semid owner perms nsems Mount Namespace Mount Namespace 可以通过隔离挂载点，为各个进程提供单独的文件视图。 在不同 Namespace 的进程中， 看到的文件系统层次是不一样的。在 Mount Namespace 中调用 mount() umount() 仅仅只会影响当前 Namespace 内的文件系统 ，而对全局的文件系统是没有影响的。\nmount/umount 函数原型： #include \u0026lt;sys/mount.h\u0026gt; int mount(const char* source, const char* target, const char* filesystemtype, unsigned long mountflags, const void* data); int umount(const char *file); shell mount [-t 系统类型] [-L 卷标名] [-o 特殊选项] [-n] 设备文件名 挂载点 umount 挂载点 go 代码如下：\nfunc main() { var cmd = exec.Command(\u0026#34;sh\u0026#34;) cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 验证挂载点被隔离 首先在 Linux Terminal 下执行 ps -ef，这个命令会从 /proc 目录下读取数据获取到进程信息。\n# linux terminal $ ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 14:39 ? 00:00:00 /sbin/init root 25 1 0 14:39 ? 00:00:00 /usr/lib/systemd/systemd-journald root 30 1 0 14:39 ? 00:00:00 /usr/lib/systemd/systemd-udevd dbus 55 1 0 14:39 ? 00:00:00 /usr/bin/dbus-daemon --system --address=systemd: --nofo root 56 1 0 14:39 ? 00:00:00 /usr/sbin/sshd -D -oCiphers=aes256-gcm@openssh.com,chac root 66 56 0 14:40 ? 00:00:00 sshd: root [priv] root 68 66 0 14:40 ? 00:00:00 sshd: root@pts/1 root 69 68 0 14:40 pts/1 00:00:00 -bash root 82 69 0 14:40 pts/1 00:00:00 ps -ef 回到 main 进程中，继续使用 ps -ef 先看一下进程\n观察一下，可以发现目前 main 可以看到的文件视图是和 linux 其他是一样的\n使用 mount --make-rprivate / 把挂载点设置私有，防止 mount 影响到其他 namespace\n执行 mount -t proc proc /proc，把 proc 文件系统挂在到 /proc 目录下\n# main $ ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 14:39 ? 00:00:00 /sbin/init root 25 1 0 14:39 ? 00:00:00 /usr/lib/systemd/systemd-jou root 30 1 0 14:39 ? 00:00:00 /usr/lib/systemd/systemd-ude dbus 55 1 0 14:39 ? 00:00:00 /usr/bin/dbus-daemon --syste root 56 1 0 14:39 ? 00:00:00 /usr/sbin/sshd -D -oCiphers= root 66 56 0 14:40 ? 00:00:00 sshd: root [priv] root 68 66 0 14:40 ? 00:00:00 sshd: root@pts/1 root 69 68 0 14:40 pts/1 00:00:00 -bash root 83 56 0 14:41 ? 00:00:00 sshd: root [priv] root 85 83 0 14:41 ? 00:00:00 sshd: root@pts/2 root 140 85 0 14:41 pts/2 00:00:00 /root/porrima/executables-WI root 153 140 0 14:41 pts/2 00:00:00 sh root 154 153 0 14:41 pts/2 00:00:00 ps -ef $ mount --make-rprivate / # 把根节点设置私有，防止 shared subtree 影响到其他 namespace $ mount -t proc proc /proc # 把 proc 挂在到 /proc 目录下 在 main 进程内执行 ps -ef，读取一下 /proc 下的进程信息，可以发现进程少了非常多，说明 mount 生效\n# main $ ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 14:41 pts/2 00:00:00 sh root 7 1 0 14:43 pts/2 00:00:00 ps -ef 回到 Linux Terminal 中，使用 ps -ef 查看进程\n# linux terminal $ ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 14:39 ? 00:00:00 /sbin/init root 25 1 0 14:39 ? 00:00:00 /usr/lib/systemd/systemd-journald root 30 1 0 14:39 ? 00:00:00 /usr/lib/systemd/systemd-udevd dbus 55 1 0 14:39 ? 00:00:00 /usr/bin/dbus-daemon --system --address=systemd: --nofo root 56 1 0 14:39 ? 00:00:00 /usr/sbin/sshd -D -oCiphers=aes256-gcm@openssh.com,chac root 66 56 0 14:40 ? 00:00:00 sshd: root [priv] root 68 66 0 14:40 ? 00:00:00 sshd: root@pts/1 root 69 68 0 14:40 pts/1 00:00:00 -bash root 83 56 0 14:41 ? 00:00:00 sshd: root [priv] root 85 83 0 14:41 ? 00:00:00 sshd: root@pts/2 root 140 85 0 14:41 pts/2 00:00:00 /root/porrima/executables-WIPxpUrEfN/___docker_linux_li root 153 140 0 14:41 pts/2 00:00:00 sh root 162 69 0 14:43 pts/1 00:00:00 ps -ef 可以发现在 Linux 本地进程信息并未改变，这就表明 Mount Namespace 成功隔离了 main 的文件视图\nUser Namespace User Namespace 用来是隔离用户的用户组 ID。\n在 User Namespace 外的一个普通用户可以映射为一个 root 用户\nfunc main() { var cmd = exec.Command(\u0026#34;sh\u0026#34;) cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS | syscall.CLONE_NEWUSER, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 验证 User 被隔离 分别在 main 和 linux terminal 执行 id 命令，查看当前用户是否相同\n# linux terminal $ whoami root $ id uid=0(root) gid=0(root) groups=0(root) # main $ whoami nobody $ id uid=65534(nobody) gid=65534(nobody) groups=65534(nobody) 可以发现两个 User 并不相同，这就表明 User 成功被隔离\nNetwork Namespace Network Namespace 用来隔离网络栈\n在 Network Namespace 中 Network Device port Socket firewall等网络环境都是独立的。\n代码如下：\nfunc main() { var cmd = exec.Command(\u0026#34;sh\u0026#34;) cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWIPC | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS | syscall.CLONE_NEWUSER| syscall.CLONE_NEWNET, } cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr if err := cmd.Run(); err != nil { log.Fatal(err) } } 验证 Network 是否被隔离 我们使用 ifconfig 查看网络配置\n# linux terminal sh-4.4$ ifconfig eth0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 172.17.0.2 netmask 255.255.0.0 broadcast 172.17.255.255 ether 02:42:ac:11:00:02 txqueuelen 0 (Ethernet) RX packets 747 bytes 6368553 (6.0 MiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 721 bytes 85839 (83.8 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73\u0026lt;UP,LOOPBACK,RUNNING\u0026gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1000 (Local Loopback) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # main $ ifconfig 我们发现，对于 main 进程来说没有发现任何网络设备，可以肯定 main 进程的网络已经被隔离开了。\nSummary Namespace 是 Linux 内核用来隔离内核资源的方式。 我们可以使用 Namespace 让不同的进程的资源隔离开，同时让他们只能看到自己的东西，只能操作自己的东西，而感受不到其他 Namespace 的进程的存在，从而实现一种「虚拟化」。\n","date":"2022-11-09T00:00:00Z","image":"https://yanghaoyu.xyz/assets/img/hero/imitate-docker.drawio.png","permalink":"https://yanghaoyu.xyz/b/porrima/1.linux-namespace/","title":"「手写 Docker」 1. 使用 Namespace 隔离资源"},{"content":"改变名字可能是最常用的重构手法，包括：\n改变函数声明 变量改名 字段改名 改名不仅仅是修改名字而已。如果你想不出一个好名字，说明背后很可能潜藏着更深的设计问题。\n","date":"2022-10-21T00:00:00Z","image":"https://yanghaoyu.xyz/assets/img/hero/refactoring.drawio.png","permalink":"https://yanghaoyu.xyz/b/refactor-mysterious-name/","title":"「重构」代码的坏味道 - 1. Mysterious Name"},{"content":"为什么要合并重复代码呢？因为一旦有重复代码存在，那就表明你阅读这些代码就要加倍小心，注意细微差异。\n最单纯的重复代码是：同一个类的两个函数含有相同的表达式。 针对这种情况，你需要做的就是采用 提炼函数 来抽取出重复代码。\n如果重复代码只是相似，可以采用 移动语句 把相似的部分放在一起以便提炼函数\n如果重复代码在同一父类的不同子类中，可以考虑采用 函数上移 以便更好地复用代码\n","date":"2022-10-22T00:00:00Z","image":"https://yanghaoyu.xyz/assets/img/hero/refactoring.drawio.png","permalink":"https://yanghaoyu.xyz/b/refactor-duplicated-code/","title":"「重构」代码的坏味道 - 2. Duplicated Code"},{"content":"尽可能地分解函数，哪怕替换后的函数调用动作比函数自身还长。\n这是因为，关键并不在于函数的长度，而是在于函数能够「做什么」和「如何做」之间的语义差距。\n","date":"2022-10-23T00:00:00Z","image":"https://yanghaoyu.xyz/assets/img/hero/refactoring.drawio.png","permalink":"https://yanghaoyu.xyz/b/refactor-long-function/","title":"「重构」代码的坏味道 - 3. Long Function"},{"content":"如果可以向某个参数发起查询而获得另外一个参数的值，那么就可以 以查询取代传参 去掉参数\n如果你发现你正在从现有的数据结构中抽取出很多数据项，那么可以考虑 保持对象完整 直接传入原来的数据结构\n如果某几项参数总是同时出现，可以考虑 引入参数对象\n","date":"2022-10-24T00:00:00Z","image":"https://yanghaoyu.xyz/assets/img/hero/refactoring.drawio.png","permalink":"https://yanghaoyu.xyz/b/refactor-long-parameter-list/","title":"「重构」代码的坏味道 - 4. Long Parameter List"},{"content":"全局变量很容易造成很多诡异的 Bug，因为在代码库的任何一个地方都可以修改他。\n首先的防御手段就是 封装变量，每当我们看到可能被各处代码污染的数据，就应该考虑封装这个变量，控制对这个变量的访问。\n如果可以，应该尽可能地保持全局变量不被修改。\n","date":"2022-10-27T00:00:00Z","image":"https://yanghaoyu.xyz/assets/img/hero/refactoring.drawio.png","permalink":"https://yanghaoyu.xyz/b/refactor-global-data/","title":"「重构」代码的坏味道 - 5. Global Data"},{"content":"在 Buffer Pool 中默认的缓存页和磁盘上的页是一样的大小，16KB。 缓存页中大致包含了该页的表空间编号、页号、缓存页的地址、链表节点信息、一些锁信息以及 LSN 信息\nBuffer Pool 内存结构 每个控制块大约占用缓存页大小的 5%，系统变量 innodb_buffer_pool_size 是不包含这部分控制块占用的内存空间大小，那么 InnoDB 在为 Buffer Pool 向操作系统申请连续的内存空间时，这片连续的内存空间一般会比 innodb_buffer_pool_size 的值大 5% 左右。\nfree 链表 在 MySQL 启动时，会对 Buffer Pool 进行初始化，划分出控制块和缓存页，使用 free 链表 保存未使用的控制块，可见在最开始时，所有控制块都会被加入 free 链表。当需要使用时，就从这条链表中取出一个控制块，填入相关信息，然后从链表中删除\n使用 hash 加速查找 为了加速缓存页的查找，InnoDB 使用表空间号 + 页号作为 key，缓存页作为 value 创建一个哈希表，在需要访问某个页的数据时，先从哈希表中根据表空间号 + 页号看看有没有对应的缓存页，如果有，直接使用该缓存页就好，如果没有，那就从 free 链表中选一个空闲的控制块，然后把磁盘中对应的页加载到该控制块对应的缓存页的位置。\nflush 链表 当一个缓存页被修改了，这个页将会被标记为脏页，这些脏页并不是直接就写入粗盘，而是先放入 flush 链表，等到一个合适的时间再写入磁盘，这样减少了 IO 次数，提高了性能。在结构上 flush 链表和 free 链表差不多\n对 LRU 进行优化 Buffer Pool 并不是使用传统的 LRU，它还对 LRU 做了许多优化\n预读 预读主要分为线性预读和随机预读\n线性预读\nInnoDB 的提供了一个系统变量 innodb_read_ahead_threshold(default 56)，如果顺序访问了某个区（extent）的页面，超过这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到 Buffer Pool 的请求，由于是异步读取(底层使用AIO)，那么从磁盘中加载这些被预读的页面并不会影响到当前工作线程的正常执行。\n随机预读\n如果 Buffer Pool 中已经存在某个区的 13 个连续的页面，不管这些页面是不是顺序读取的，都会触发一次异步读取本区中所有其的页面到 Buffer Pool 的请求。这项功能默认关闭，可以通过 innodb_random_read_ahead 系统变量进行开启\n冷热分离 预读机制极大地提高语句执行的效率，当然这只是在预读的页面能使用到的情况下，如果用不到，那么这些页面将会把原先那些有用的缓存刷掉。类似的，一次全表扫描，也会把原来有用的缓存页逐出，但是全表扫描的频率是很低的，又可能访问一次之后，又要等很久才进行一次全表扫描，这样来看，一次全表扫描就把缓存页逐出的操作是非常不划算的。\n为了解决以上两个问题，InnoDB 对 LRU 链表做了冷热分离。\nLRU 链表被分为两部分：old 区 young 区，其中 old 区占 37%\n具体的机制是这样的：\n解决预读的问题 当磁盘上的某个页面在初次加载到 Buffer Pool 中的某个缓存页时，该缓存页对应的控制块会被放到 old 区域的头部。这样针对预读到 Buffer Pool 却不进行后续访问的页面就会被逐渐从 old 区域逐出，而不会影响 young 区中被使用比较频繁的缓存页。\n解决全表扫描的问题 全表扫描的特点是频率低，因此 InnoDb 规定：对 old 区中的页面第一次访问时就要在它的控制块中记录访问时间，如果后续的访问时间与第一次访问的时间小于某个时间，则该页面就不会被移动到 young 区域的头部。这个时间可以由系统变量 innodb_old_blocks_time 控制。这样一来，当全表扫描的时候，由于页面快速的访问，逐出的全部是 old 区的页面，而 young 区 那些频繁访问的页面就留在了内存中。\n把脏页写入磁盘 在 InnoDB 中，存在一个线程专门用于把脏页写入磁盘，这条线程主要关注两个地方 LRU 链表 flush 链表\nLRU 链表\n后台线程会定时从 LRU 链表尾部开始扫描一定数量的页面(通过系统变量innodb_lru_scan_depth 来指定)，如果发现脏页，则会把它们刷新到磁盘。这种刷新方式被叫做 BUF_FLUSH_LRU\nflush 链表\n后台线程也会定时从 flush 链表中刷新一部分页面到磁盘，这种刷新方式叫BUF_FLUSH_LIST\n如果后台写入磁盘的线程比较慢，此时又希望缓存一个页面到 Buffer Pool，那么这时就会先看看 LRU 链表尾部有没有未修改的页面，如果没有将会把 LRU 尾部的一个脏页写入磁盘，然后再把新的页面缓存，这就是 BUF_FLUSH_SINGLE_PAGE。\n","date":"2022-04-30T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/bufferpool.png","permalink":"https://yanghaoyu.xyz/b/mysql-buffer-pool/","title":"MySQL - Buffer Pool"},{"content":"全局锁 全局锁是对整个数据库实例加锁，主要应用在做全库的逻辑备份。 如果在主库上做备份，那么备份期间主库都都无法执行更新操作，如果在从库上做备份，那么从库无法执行主库同步过来的 binlog，造成了主从同步延迟\n使用 flush tables with read lock 即可对整个数据库实例加锁，那么其他客户端执行更新操作将会被阻塞\n表级锁 1. 表锁 表锁对整张表加锁，开销小，加锁快，但是锁定力度大，很容易发生锁冲突，并发度低，MyISAM 和 InnoDB 都支持表锁 表锁分为读锁和写锁,读锁只兼容读锁，写锁则与写锁和读锁都互斥\n2. 元数据锁 (Meta Data Lock, MDL) 元数据锁是 mysql 5.5 新增的锁，元数据锁由 mysql 来控制，无需显示使用，主要是用于避免 DML 和 DDL 冲突，保证读写的正确性。当对某张表进行增删改查的时候会自动加上 MDL 读锁，当对表结构进行修改时会自动加上 MDL 写锁\n3. 意向锁 当一条 sql 加行锁之后将会向整张表添加意向锁，此后如果尝试向该表添加表锁，那么会提前检查要添加的表锁和已经存在的意向锁是否兼容，如果不兼容将会阻塞，无法加锁\n意向锁分为 意向读锁(IS), 意向写锁(IX)\n兼容情况：\nIS 与表级读锁兼容，与表级写锁不兼容 IX 与表级读锁和表级写锁都互斥 意向锁之间不会互斥 具体如下表：\n兼容性 X IX S IS X 不兼容 不兼容 不兼容 不兼容 IX 不兼容 兼容 不兼容 兼容 S 不兼容 不兼容 兼容 兼容 IS 不兼容 兼容 兼容 兼容 行级锁 行级锁每次锁住整行数据，粒度最小，发生锁冲突的概率最低，并发度最高，它是通过对索引项加锁实现的\n1. 记录锁 (Record Lock) 行锁：锁定单行记录的锁，防止其他事务对该记录进行修改\nSQL 类型 说明 insert 写锁 自动加锁 update 写锁 自动加锁 delete 写锁 自动加锁 select 无锁 需要手动加锁 select \u0026hellip; in share mode 读锁 为 select 加上读锁 select \u0026hellip; for update 写锁 为 select 加上写锁 2. 间隙锁 (Gap Lock) MySQL 在 REPEATABLE READ 隔离级别下是可以解决幻读问题的，主要解决方案有两种\nMVCC 加锁 在使用加锁解决幻读时有个大问题，就是事务在第一次执行读取操作时，幻影记录还不存在，我们并不能为这些幻影记录加上记录锁。因此 InnoDB 就把前一个记录和该记录的链接锁上，确保不能在该记录的前面插入新的数据，这就是 Gap Lock (间隙锁)\n如图所示，为id = 9 的记录加上一把间隙锁，此时如果某个事务要在 4 ～ 9 之间插入一条记录，那么由于这个间隙锁的存在，这操作将会被阻塞，直到这个间隙锁被释放，才会插入新的记录。对于第一条记录，和最后一条记录，由于有 Infimum 和 Supremum 的存在，也是可以加锁成功的\n3. 临键锁 (Next-key Lock) 临键锁就相当于间隙锁 + 记录锁，既可以确保记录的前方不被插入新记录，也可以保证该记录不被修改\n","date":"2022-04-30T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/gaplock.png","permalink":"https://yanghaoyu.xyz/b/mysql-%E9%94%81/","title":"MySQL - 锁"},{"content":"在 多 Reactor + 多线程 中，依旧有一个主 Reactor（暂且称为 Boss），Boss 主要负责监听 Accept 事件，然后把这些事件合理地分到每个子 Reactor（Worker）。而每个 Worker 有拥有一个属于自己的 Selector，当 Worker 拿到 Boss 分配的事件，会把这个事件直接注册到自己的 Selector 中，这样一部分流量就被 Worker 承担了，而 Boss 只需要按一个合理的策略分配事件就行了\nJava 实现：\nBoss 是主 Reactor，有四个字段\nSelector - Boss 自己的 Selector，监听 Accept 事件 ssc - Selector 监听的端口 workers - Boss 拥有的 Worker，Boss 监听到 Accept 事件 会把分配到 Worker index - 下一个可用的 Worker class Boss implements Runnable { Selector selector; ServerSocketChannel ssc; Worker[] workers = new Worker[]{new Worker(0), new Worker(1)}; AtomicInteger index = new AtomicInteger(); public Boss() { try { selector = Selector.open(); ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); ssc.bind(new InetSocketAddress(8080)); ssc.register(selector, SelectionKey.OP_ACCEPT); } catch (IOException e) { e.printStackTrace(); } } @Override public void run() { try { while (true) { selector.select(); Iterator\u0026lt;SelectionKey\u0026gt; iter = selector.selectedKeys().iterator(); while (iter.hasNext()) { SelectionKey key = iter.next(); iter.remove(); // 监听 accept 事件 if (key.isAcceptable()) { ServerSocketChannel c = (ServerSocketChannel) key.channel(); SocketChannel sc = c.accept(); sc.configureBlocking(false); System.out.println(sc.getRemoteAddress() + \u0026#34; connected\u0026#34;); // 选择一个 Worker，然后分配给它 chooseWorker().register(sc); } } } } catch (IOException e) { e.printStackTrace(); } } private Worker chooseWorker() { return workers[index.getAndIncrement() % workers.length]; } } Boss 是子 Reactor，有四个字段\nSelector - Work 自己的 Selector，监听自己感兴趣的事件 start - 是否开始，当 Boss 第一次使用该 Worker 会置为 true，然后启动子 Reactor 线程 tasks - 一个缓冲区，主 Reactor 会把它分配的任务放入这里，然后子 Reactor 运行的时候不仅会处理自己的任务，还要把缓冲区的任务也做了 class Worker implements Runnable { Selector selector; volatile boolean start = false; private final ConcurrentLinkedQueue\u0026lt;Runnable\u0026gt; tasks = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); int index; public Worker(int index) { try { selector = Selector.open(); this.index = index; } catch (IOException e) { e.printStackTrace(); } } public void register(SocketChannel sc) throws IOException { // 第一次使用 if (!start) { selector = Selector.open(); new Thread(this, \u0026#34;worker-\u0026#34; + index).start(); start = true; } // 放入缓冲区，等待执行 tasks.add(() -\u0026gt; { try { // 注册到自己的 Selector 中 sc.register(selector, SelectionKey.OP_READ, null); // 放入了新的 // 重新 select 一下 selector.selectNow(); } catch (IOException e) { e.printStackTrace(); } }); selector.wakeup(); } @Override public void run() { while (true) { try { selector.select(); Runnable task = tasks.poll(); // 先处理 Boss 分配的任务 if (task != null) { task.run(); } Set\u0026lt;SelectionKey\u0026gt; keys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; it = keys.iterator(); while (it.hasNext()) { SelectionKey key = it.next(); it.remove(); if (key.isReadable()) { SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); try { int read = sc.read(buffer); if (read == -1) { key.cancel(); sc.close(); } else { // read here // ... ... System.out.println(Thread.currentThread().getName() + \u0026#34;read message\u0026#34;); } } catch (IOException e) { e.printStackTrace(); key.cancel(); sc.close(); } } } } catch (IOException e) { e.printStackTrace(); } } } ","date":"2022-04-23T00:00:00Z","image":"https://pic3.zhimg.com/v2-4da008d8b7f55a0c18bef0e87c5c5bb1_r.jpg?source=1940ef5c","permalink":"https://yanghaoyu.xyz/b/netty-%E5%A4%9A%E7%BA%BF%E7%A8%8B--%E5%A4%9A-reactor/","title":"Netty - 多线程 + 多 Reactor"},{"content":"单 Reactor + 单线程 Reactor 对象通过 select 监听事件，收到事件后通过根据事件类型进行分发，让对应的对象处理具体的事件\n伪代码如下：\nvar fds = epoll() for _, fd := range fds { if isAcceptable(fd) { // 处理 accept 事件 } if isReadable(fd) { // 处理 read 事件 } // 处理其他事件 // if ... { // ... // } } 使用 Java 实现\n//建立一个 Selector Selector selector = Selector.open(); //建立服务端，而且注册到 Selector 上 ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(8080)); serverSocketChannel.configureBlocking(false); // ServerSocketChannel 只支持 ACCEPT 事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\u0026#34;服务器已启动！\u0026#34;); while (true) { selector.select(); Iterator\u0026lt;SelectionKey\u0026gt; it = selector.selectedKeys().iterator(); while (it.hasNext()) { SelectionKey selectionKey = it.next(); it.remove(); if (selectionKey.isAcceptable()) { // accept 事件在这里处理 SocketChannel socketChannel = ((ServerSocketChannel) selectionKey.channel()).accept(); socketChannel.configureBlocking(false); socketChannel.register(selector, SelectionKey.OP_READ); } if (selectionKey.isReadable()) { // read 事件在这里处理 } } } 单线程 + 单 Reactor 的模型实现简单，但对多核 CPU 利用率低，同时如果某个请求处理较长，也会造成响应的延迟\nRedis 就是使用的是这种模型，因为作为一个内存数据库，性能瓶颈并不在 CPU，而在于 IO\n单 Reactor + 多线程 在 单 Reactor + 多线程，Reactor 依旧分发各个事件给对应的对象，但是每个对象都不再 reactor 线程中执行， 而是会 fork 一个新的线程处理请求，也可以使用线程池复用线程\nJava 实现如下：\nSelector selector = Selector.open(); ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(8080)); serverSocketChannel.configureBlocking(false); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\u0026#34;服务器启动成功\u0026#34;); while (true) { selector.select(); Iterator\u0026lt;SelectionKey\u0026gt; it = selector.selectedKeys().iterator(); while (it.hasNext()) { SelectionKey selectionKey = it.next(); it.remove(); if (selectionKey.isAcceptable()) { // 主线程处理 accept SocketChannel socketChannel = ((ServerSocketChannel) selectionKey.channel()).accept(); socketChannel.configureBlocking(false); socketChannel.register(selector, SelectionKey.OP_READ); System.out.println(\u0026#34;收到新连接：\u0026#34; + socketChannel.getRemoteAddress()); } if (selectionKey.isReadable()) { // 另外一个线程处理 read 事件 POOL.submit(() -\u0026gt; { // do something... }); } } } 这种方式相对于 单线程 + 单 Reactor 来说，对多核 CPU 的利用率更高了，但是引入了多线程，是的程序更加复杂。\n除此之外，单 Reactor 在面对瞬间高并发的场景，Reactor 线程 承担了所有事件的监听、分发、响应，有可能性能大幅度降低\n","date":"2022-04-23T00:00:00Z","image":"https://pica.zhimg.com/v2-614eb69d0186c32de123115b10c3c682_r.jpg?source=1940ef5c","permalink":"https://yanghaoyu.xyz/b/%E9%AB%98%E6%80%A7%E8%83%BD-io-reactor-%E6%A8%A1%E5%BC%8F/","title":"高性能 IO - Reactor 模式"},{"content":"《 UNIX 网络编程 》把 IO 模型主要分为 5 种\n阻塞 IO 模型 非阻塞 IO 模型 IO 多路复用模型 信号驱动 IO 模型 异步 IO 模型 1. 阻塞 IO 阻塞 IO 模型 是最简单的模型，这种模型程序发起 recvform 系统调用，一直阻塞，直到 OS kernel 把数据准备好，再把数据拷贝到用户空间，才会返回到程序，让程序处理数据\n由此可见，阻塞 IO 模型 会在两个地方进行阻塞\n在发起 recvform 之后一直等待数据准备完毕 在数据准备好后需要等待 OS 内核拷贝到用户空间程序 模型简单，实现难度低，适用于并发量较小的应用开发，但是由于整个过程都被阻塞，性能较低\n单线程 for true { var client = accept(serverFd) // 等待客户端建立连接 var n int = read(client, buffer) // 读入客户端发来的数据, 网卡 -\u0026gt; 内核缓冲区 -\u0026gt; 用户缓冲区 handle(buffer) // 处理数据 close(serverFd) // 关闭连接 } 多线程 服务端使用多线程，可以完成并发处理，但是随着线程数的变多，占用的内存会越来越大，上下文的开销也会越来越大, 为每一个连接都开启一个线程也不一定是一个好的选择\nfor true { var client = accept(serverFd) // 等待客户端建立连接 go func() { var n int = read(client, buffer) // 读入客户端发来的数据, 网卡 -\u0026gt; 内核缓冲区 -\u0026gt; 用户缓冲区 handle(buffer) // 处理数据 close(serverFd) // 关闭连接 } } 2. 非阻塞 IO 模型 非阻塞 IO 模型 相对于 阻塞 IO 模型 来说，多了一个轮询机制\n发起 recvform 系统调用之后，os kernel 会看看数据是否准备好，如果没有准备好,则会返回 EWOULDBLOCK 错误码, 收到错误码之后，程序便知道了数据还没准备好，就可以先去处理其他任务，如果 os kernel 发现数据已经准备好了，就会把数据拷贝到用户空间(阻塞)，让程序进行处理\nsetNonBlocking(serverFd) var clientFds = make([]fd) for true { // 检查是否有新的连接 var clientFd = accept(serverFd) if clientFd != nil { append(clientFds, clientFd) } else { // 做点其他事 } // 遍历所有连接, 处理数据 for _, clientFd := range clientFds { var n int = read(clientFd, buffer) if n != -1 { // 数据到达 handle(buffer) } else { // 数据没到的时候可以考虑做点其他事 } } } 我们使用一个数组 clientFds 存放客户端连接，在每次检查是否有新的连接的时候去处理旧的客户端连接发过来的数据，这样使用一个线程就完成了对多个客户端连接的处理\n3. IO 多路复用 非阻塞 IO 模型 在一个死循环中不断遍历 clientFds 发起 recvform 系统调用，这其实是浪费了很大一部分 CPU 资源，是非常不划算的，所以还得依赖于操作系统，我们把感兴趣的 fd 发送给 OS，让 OS 在内核中进行遍历确定哪些 fd 可读可写，然后把可读可写的 fd 返回给程序，让用户线程处理\n1. select var clientFds = make([]fd) for true { var clientFd = accept(serverFd) // 把新的连接添加进去, 让 OS 遍历 append(clientFds, clientFd) var fds = select(clientFds) // 让 OS 去遍历数组 // 再次遍历数组 for _, fd := range fds { // 只处理已经准备好的 if fd != -1 { var n = read(fd, buffer) // 处理数据 handle(buffer) } } } 相比起 非阻塞 IO，使用 select 时的系统调用次数大大降低 (1 次 select+n 次 read) 但是 select 仍有缺点，主要有三个\nselect 需要把传入的 clientFds 再拷贝一份到内核 os kernel 遍历 clientFds 依旧是同步的 返回的仅仅是可读文件描述的个数 上面我都是用 golang 伪代码来描述的，下面是 select 函数签名\nint select( int nfds, // 监听多少个文件描述符, 单个线程最多为 1024 fd_set *readfds, // 可读的文件描述符集合, 出参 fd_set *writefds, // 可写的文件描述符集合, 出参 fd_set *exceptfds, // 异常发生文件描述符集合, 出参 struct timeval *timeout // 超时时间, 设置为 NULL 则阻塞, 设置为 0 则轮询 ); struct timeval { time_t tv_sec; // 秒 suseconds_t tv_usec; // 微秒 }; 2. poll poll 和select 并无太大区别，仅仅去掉了单个线程最多监听 1024 个 fd 限制\n3. epoll epoll 真正地解决了 select 的三个问题\n在内核中保存一份 fd 的集合，程序只需告诉 OS 需要修改的部分即可 OS 采用异步 IO 事件找到就绪的 fd，而不通过轮询 返回已经就绪的 fd 集合，无需程序再次遍历整个文件描述符集合找到就绪的 fd epoll主要有三个函数\n创建一个 epoll 句柄 int epoll_create(int size); 向内核添加，修改或删除要监听的文件描述符 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 让操作系统检查 fd 并把就绪的 fd 返回 int epoll_wait(int epfd, struct epoll_event *events, int max_events, int timeout); 伪代码如下:\n// 在内核中创建 epoll 对象 epfd = epoll_create(256); // 放入想监听的 fd epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, \u0026amp;ev); while(1) { // 让 OS 检查 fd int nfds = epoll_wait(epfd, events , 10, 0); for(int i=0; i\u0026lt; nfds; ++i) { if(events[i].data.fd == listenfd) { // 处理 accept 事件 connfd = accept(listenfd); // 新连接放入 epoll epoll_ctl(epfd, EPOLL_CTL_ADD, connfd,\u0026amp;ev); } else if (events[i].events\u0026amp;EPOLLIN) { // 处理 read 事件 read(sockfd, buffer, MAXLINE); handle(buffer) } else if(events[i].events\u0026amp;EPOLLOUT) { // 处理 write 事件 write(sockfd, buffer, n); handle(buffer) } } } 4. 信号驱动 IO 模型 程序发起一个 IO 操作，会向内核注册一个信号处理函数，然后进程立即返回，当内核数据就绪后(未拷贝到用户空间)会发送一个信号给进程，此时进程就能在信号处理函数中读取数据。\n5. 异步 IO 模型 程序发送一个 IO 操作，OS 立刻返回，内核等待数据报准备好并拷贝到用户空间，再通知进程，进程再处理数据\n","date":"2022-04-22T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/bio.png","permalink":"https://yanghaoyu.xyz/b/unix-io-%E6%A8%A1%E5%9E%8B/","title":"UNIX IO 模型"},{"content":"从哪里加载? 从本地磁盘加载 (class 文件, jar 包, zip 包) 通过网络资源加载 从数据库中提取 class 文件 java 文件动态编译为 class 文件 一个类的生命周期 加载 -\u0026gt; 验证 -\u0026gt; 准备 -\u0026gt; 解析 -\u0026gt; 初始化 这里的几个阶段是按顺序开始(而不保证是按顺序进行的) 在这五个阶段中, 加载 验证 准备 初始化这四个阶段顺序是确定的, 而解析阶段则不一定,它在某些情况下可以在初始化阶段之后开始,这是为了支持 Java 语言的运行时绑定（也成为动态绑定或晚期绑定）。\n加载 在 java 中,一个 class 都是 ClassLoader 加载的, 加载时类加载的第一个阶段\n在这个阶段, JVM 把类读入内存 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。\n加载阶段完成后, 虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中, 而且在 Java 堆中也创建一个 java.lang.Class 类的对象, 这样便可以通过该对象访问方法区中的这些数据\n验证 验证是为了确保 Class 文件是否是合法的,主要检验以下 4 个部分\n文件格式：是否以 0xCAFEBABE 开头,版本号是否正确, 常量池中的常量是否有不被支持的类型 元数据：对字节码描述的信息进行语义分析, 以保证其描述的信息符合 Java 语言规范的要求 字节码：通过数据流和控制流分析, 确保程序语义是合法的 符号引用：确保后续的解析阶段能正确执行。 准备 准备阶段会为类变量分配内存并设置类变量初始值的阶段, 这些内存都将在方法区中分配 值得注意的是: 在这里分配的都是默认的 0 值, 例如: 0, false, null, 并不是程序员所指定的值, 如果使用 final 修饰,那么才会在这里初始化为程序员指定的值\npublic static int i = 1 将被分配为 0 public static final int j = 1 将被分配为 1 解析 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程, 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符 7 类符号引用进行\n初始化 初始化,正式为类变量设置初始值, 也就是程序员所指定的值\npublic static int i = 1 将在此时被初始化为 1\n初始化步骤 假如这个类还没有被加载和连接, 则程序先加载并连接该类 假如该类的直接父类还没有被初始化, 则先初始化其直接父类 假如类中有初始化语句, 则系统依次执行这些初始化语句 初始化时机 只有当对类的主动使用的时候才会导致类的初始化, 主要包括:\nnew Instance 访问某个类或接口的静态变量, 或者对该静态变量赋值 调用类的静态方法 反射使用到此类 初始化某个类的子类, 则其父类也会被初始化 Java 虚拟机启动时被标明为启动类的类, 直接使用 java 命令来运行某个主类 总之, 在第一次使用到时初始化\n双亲委派机制 在 JDK 中内置了 3 种 ClassLoader\nBootstrapClassLoader ExtClassLoader AppClassLoader 这三种类加载器主要的职责并不相同\nBootstrapClassLoader, 主要负责加载 JDK 中的类( %JDK_HOME%\\jre\\lib下的类 ), 或被 -Xbootclasspath 参数指定的路径中的, 启动类加载器是无法被 Java 程序直接引用的\nExtClassLoader,主要负责加载 JDK 中内部实现的扩展类(%JDK_HOME%\\jre\\lib\\ext下的类),该加载器由 sun.misc.Launcher$ExtClassLoader 实现, 开发者可以直接使用扩展类加载器。\nAppClassLoader, 主要负责程序中的类文件的加载, 该类加载器由 sun.misc.Launcher$AppClassLoader 来实现, 开发者可以直接使用该类加载器, 并且它是默认的类加载器。\n加载器在加载过程中, 先把类交由父类加载器进行加载, 父类加载器没找到才自身加载, 这就是双亲委派机制\n具体来讲就是以下规则:\n当 AppClassLoader 加载类时, 它并不会先自己加载这个类, 而是先把类加载请求委派给父加载器 ExtClassLoader 当 ExtClassLoader 加载类时, 它也不会首先自己去加载这个类, 而是把类加载请求委派给父加载器 BootStrapClassLoader 去完成 若 BootStrapClassLoader 加载失败会使用 ExtClassLoader 来尝试加载 若 ExtClassLoader 加载失败, 则会使用 AppClassLoader 来加载 若 AppClassLoader 加载失败, 就报出异常 ClassNotFoundException 源码如下:\nprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded // 首先 判断是否被加载过 Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { // 让父加载器加载 if (parent != null) { c = parent.loadClass(name, false); } else { // 如果父加载器不存在 // 就检查是否是由启动类加载器加载的类 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } private Class\u0026lt;?\u0026gt; findBootstrapClassOrNull(String name) { if (!checkName(name)) return null; return findBootstrapClass(name); } 双亲委派最主要的好处就是: 防止了 JVM 中出现多份相同的字节码, 同时也保证了 JDK 基础类库的安全(自己定义的java.lang.Object并不会被加载)\n","date":"2022-04-18T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/blog-hero-jvm-loadclass.png","permalink":"https://yanghaoyu.xyz/b/jvm-%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE/","title":"JVM - 类的加载和双亲委派"},{"content":" sds struct struct sdshdr { // 记录字符串的长度 int len; // 记录未使用的字节数量 int free; // 一个柔性数组, 用于保存字符串, 字符串中没有数据的时候不会占用空间 (C99特性) char[] buffer; } int len int free char[] buffer 内存重分配 在 sds 进行扩展时, redis 会对其进行预分配, 防止多次系统调用陷入内核, 具体规则如下:\n在修改之后, 如果 sds 的长度小于 1MB, 那么额外分配和 len 一样大的空间 比如分配之后 len == 20, 那么 redis 会额外分配 20byte 空间,那么 buffer 总共占 20 + 20 + 1 = 41byte\n如果长度大于 1MB, 那么只会额外分配 1MB 比如 分配完毕之后是 2MB, 那么将会多分配 1MB, 因此 buffer 总共占 2MB + 1MB + 1byte\n惰性空间释放 在 sds 变短时, 原来的空间也并不会被释放, 而是会把多的空间大小保存到 free 属性中, 以便后续使用, 这样也减少了空间多次分配, 减少了系统调用\n总结一下, sds 有以下优点:\no(1) 获取字符串 缓冲区不溢出 内存分配次数大大降低 二进制安全, 可以存储任何数据 兼容部分 C 原生字符串 ","date":"2022-03-02T00:00:00Z","image":"https://res.weread.qq.com/wrepub/epub_622000_18","permalink":"https://yanghaoyu.xyz/b/redis-simple-dynamic-string/","title":"Redis - Simple Dynamic String"},{"content":" MySQL 中有 4 中行格式 Compact, Redundant, Dynamic, Compressed\n我们可以在创建表时指定所使用的的行格式\ncreate table table_name (col int) row_format = ${row_format_name} Compact 变长字段长度列表 NULL 值列表 记录头 列 1 列 2 列 3 \u0026hellip; 变长字段长度列表 用于保存变长字段的长度, 例如 varchar(10) 这是一个变长类型, 那么就需要把该字段实际占用的字节数保存起来. 例如, 对于('1111','11','1')这样一条记录, 每个字段都是 varchar 类型,并且采用 ASCII 字符集, 那么就需要在这个列表中存入 0x1, 0x2, 0x4 (逆序存放)\n1 2 4 NULL 值列表 记录头 列 1 列 2 列 3 \u0026hellip; 如果字符串的长度太长 那么就可能需要 2 byte 或者更多字节来存储 (例如: 一个长度为 1024 字符串,1024 不可能用 1 byte 存下), 另外, 对于变长字符集 (例如: utf8 ), 情况会更复杂, 这是因为 ascii 是定长字符集,每个字符只占用 1 byte, 而 utf8 在 MySQL 中默认是 utf8mb3(不是 utfmb4,utfmb4 还支持 emoji :smile:), 每一个字符可以占用 1~3 byte. 在 MySQL 使用 W 表示某个字符集中一个字符占用最大的字节数, utf8 是 3, gbk 是 2, ascii 是 1, 使用 M 表示最多能存储的字符数, 那么某个数据类型最多占用 M * Wbyte, 而使用 L 表示实际占用字节长度 ( '1111' 就是 4 byte)\nMySQL 使用如下规则来确定使用多少字节来保存变长字段的长度:\nif M * W \u0026gt; 255 \u0026amp;\u0026amp; L \u0026gt; 127 { use 2 byte } else { use 1 byte } 如果 M * W 超过 255 byte 并且 L 超过 127 byte, 则使用 2 byte, 否则使用 1 byte。那么 2 byte 就能够存储了吗?\n是的, MySQL 规定一条记录最多占用 65535 byte(包括 变长字段的长度列表 NULL 值列表 真实数据 ,不包括 记录头 隐藏列 )\n由此,我们可以计算出 varchar 能存储的最大字符数\nutf8 下最大字符数 不声明 not null 变长字段长度列表 2 byte, NULL 值列表 1 byte, 每个字符占用 3 byte(英文虽然是 1 byte,也按 3 byte 算)\n因此 最大字符数数 = (65535 - 2 - 1) / 3 = 21844\ngbk 下最大字符数 变长字段长度列表 2 byte, NULL 值列表 1 byte, 每个字符占用 2 byte(英文虽然是 1 byte,也按 2 byte 算)\n因此 最大字符数数 = (65535 - 2 - 1) / 2 = 32766\n注意: 这都是在只有一个字段下的情况, 更重要的是变长字段的长度列表 + NULL 值列表 + 真实数据 \u0026lt;= 65535\n一条记录数据太多怎么办? MySQL 一页占用 16k,即 16384 byte, 如果一条记录太大, 那么一个完整的页面也放不下. 对于占用空间非常大的列,Compact会先存储一部分数据(前 768 byte), 剩下的数据分别存储在其他页面(称作溢出页)中, 然后把这些页面的地址存到真实数据里, 这样就能找到完整的数据, 这就叫做行溢出\nNULL 值列表 用于保存一条记录中哪些字段是 null ,如果所有字段都声明为 not null, 那么 NULL 值列表不存在。 实际上 NULL 值列表是一个位向量\nindex 0 1 2 3 4 5 6 7 bit 0 0 0 0 0 0 0 0 例如: (null,'howieyoung',null) 的 NULL 值列表为:\nindex 0 1 2 3 4 5 6 7 bit 0 0 0 0 0 1 0 1 每一列的信息在 NULL 值列表中是逆序存放的\n第 1 列对应 7 号位, 1 表示该字段为 null\n第 2 列对应 6 号位, 0 表示该字段不为 null\n第 3 列对应 5 号位, 1 表示该字段为 null\n记录头 记录头存储了一些基本信息\n0 1 2 3 [4,7] [8,20] [21,23] [24,39] 预留 预留 delete_mask min_rec_mask n_owned heap_no record_type next_record 未使用 未使用 是否被删除 是否是 B+树的最小记录 当前记录对应的分组的记录数 当前记录在记录堆的位置信息 记录类型 下一条记录的相对位置 Redundant Redundant 是 MySQL 5.0 之前使用的一种行格式, 略.\nDynamic Dynamic 和 Compact 差不多, 是 MySQL 默认的行格式, 在处理行溢出时,它并不会像 Compact 存储前 768 byte,而是全部存在溢出页中\nCompressed Compressed 和 Dynamic 相比, Compressed 会采用压缩算法对页面进行压缩\n","date":"2022-02-14T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/blog-hero-inndb-rowformat.png","permalink":"https://yanghaoyu.xyz/b/mysql-innodb-%E8%A1%8C%E6%A0%BC%E5%BC%8F/","title":"MySQL - InnoDB 行格式"},{"content":"GC (Garbage Collectors), 垃圾收集器. 是对 GC 算法的具体实现, 在 JVM 主要有 7 中收集器,Serial,Serial Old, ParNew, Parallel Scavenge,Parallel Old,CMS,G1\nSerial 特性 Serial 是一个采用复制算法的单线程垃圾收集器, 这意味着 Serial 进行工作时,会暂停所有的用户正常工作的线程(Stop the World),效率高,\n应用场景 主要用于Young Gen的回收, 是 JVM 运行在 Client 模式下的默认新生代回收器\nParNew 特性 ParNew 实际上就是 Serial 的多线程版本\n应用场景 是 JVM 运行在 Server 模式下的首选的新生代回收器,ParNew能与CMS配合工作\nParallel Scavenge 特性 Parallel Scavenge是一个新生代收集器, 它也是采用的复制算法, 是并行的多线程收集器。这个收集器主要关注吞吐量, 吞吐量 = 运行用户代码时间 / (运行用户代码时间 + gc时间).\nGC 自适应的调节策略： Parallel Scavenge 收集器有一个参数-XX:+UseAdaptiveSizePolicy. 当这个参数打开之后, 就不需要手工指定新生代的大小(-Xmn), Eden 与 Survivor 区的比例(-XX:SurvivorRatio)、晋升老年代对象年龄(-XX:PretenureSizeThreshold)等细节参数了, 虚拟机会根据当前系统的运行情况收集性能监控信息, 动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量, 这种调节方式称为 GC 自适应的调节策略（GC Ergonomics）。\n应用场景 停顿时间越短就越适合需要与用户交互的程序, 而高吞吐量则可以高效率地利用 CPU 时间, 主要适合在后台运算而不需要太多交互的任务, Parallel Scavenge 收集器也经常被称为“吞吐量优先”收集器.\nSerial Old 特性 Serial Old 是 Serial 收集器的老年代版本, 他同样是个单线程收集器, 使用“标记整理”算法。\n应用场景 这个收集器的主要意义是给 Client 模式下的虚拟机使用 在 Server 模式下, 可以作为CMS的后备方案 Parallel Old 特性 Parallel Old 是 Parallel Scavenge 收集器的老年代版本, 使用多线程和“标记-整理”算法。\n应用场景 CMS 特性 CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器, 并发收集、低停顿是它的特点\nCMS 工作过程主要分为以下几步:\n初始标记 (initial mark)\n初始标记仅仅只是标记一下 GC Roots 能直接关联到的对象, 速度快, 需要 STW。 并发标记 (concurrent mark)\n并发标记阶段就是进行 GC Roots Tracing 的过程。 重新标记 (remark)\n重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录, 这个阶段的停顿时间一般会比初始标记阶段稍长一些, 但远比并发标记的时间短, 需要 STW。 并发清除 (concurrent sweep)\n并发清除阶段会清除对象。 CMS 默认启动的回收线程数是（CPU 数量+3）/ 4, 当 CPU 在 4 个以上时, 并发回收时垃圾收集线程不少于 25% 的 CPU 资源, 并且随着 CPU 数量的增加而下降。但是当 CPU 不足 4 个时, CMS 对用户程序的影响就可能很大。\nCMS 收集器无法处理浮动垃圾\n浮动垃圾 : 由于 CMS 并发清理阶段用户线程还在运行着, 伴随程序运行自然就还会有新的垃圾不断产生(因此需要预留有足够的内存空间给用户线程使用,如果预留的内存无法满足程序需要, 就会出现一次Concurrent Mode Failure使用Serial Old对老年代进行回收), 这一部分垃圾出现在标记过程之后, CMS 无法在当次收集中处理掉它们, 只好留待下一次 GC 时再清理掉。这一部分垃圾就称为浮动垃圾。\nCMS 收集器会产生大量空间碎片\nG1 特性 G1 是基于“标记-整理”算法实现的收集器, 引入分区的思路, 弱化了分代的概念, 合理利用垃圾收集各个周期的资源, 解决了其他收集器甚至 CMS 的众多缺陷。\n它没有新生代和老年代的概念, 而是将堆划分为一块块独立的 Region. 当进行垃圾收集时, G1 会先估计每个 Region 中垃圾的数量, 每次都从垃圾回收价值最大的 Region 开始回收, 因此可以获得最大的回收效率。\n为了防止遍历整个堆空间, 每个 Region 都有一个Remembered Set用于记录该 Region 中所有对象引用的对象所在的区域,进行可达性分析时, 只要在 GC Roots 中再加上 Remembered Set 即可防止对整个堆内存进行遍历。\n如果不计算维护 Remembered Set 的操作, G1 收集器的工作过程分为以下几个步骤：\n初始标记 STW, 仅使用一条初始标记线程对所有与 GC Roots 直接关联的对象进行标记。 并发标记 使用一条标记线程与用户线程并发执行。此过程进行可达性分析, 速度很慢。 最终标记 STW, 使用多条标记线程并发执行。 筛选回收 回收废弃对象, 此时也要 STW, 并使用多条筛选回收线程并发执行。 ","date":"2021-09-13T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/gc.png","permalink":"https://yanghaoyu.xyz/b/jvm-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/","title":"JVM - 垃圾收集器"},{"content":"\nAQS中的ConditionObject public class ConditionObject implements Condition, java.io.Serializable /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; await 将当前线程新建一个节点同时加入到条件队列中, 然后完全释放当前线程持有的锁.\n然后利用死循环检测该节点代表的线程是否出现在同步队列中(signal 会把 node 加入同步队列), 如果不存在则阻塞, 等待 signal 唤醒\npublic final void await() throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); // 添加到条件队列 Node node = addConditionWaiter(); // 完全释放锁 (重入也会被释放) int savedState = fullyRelease(node); int interruptMode = 0; // 判断是否在同步队列中, 如果不在的话阻塞该进程 (signal会把 node 加入同步队列) while (!isOnSyncQueue(node)) { LockSupport.park(this); // 如果被中断 跳出循环 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; } // 继续抢锁 if (acquireQueued(node, savedState) \u0026amp;\u0026amp; interruptMode != THROW_IE interruptMode = REINTERRUPT; // clean up if cancelled if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode)a; } private Node addConditionWaiter() { Node t = lastWaiter; // If lastWaiter is cancelled, clen out. if (t != null \u0026amp;\u0026amp; t.waitStatus != Node.CONDITION) { unlinkCancelledWaiters(); t = lastWaiter; } // 当前线程新建节点，状态 CONDITION Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node; } final int fullyRelease(Node node) { boolean failed = true; try { // 完全释放锁 int savedState = getState(); if (release(savedState)) { failed = false; return savedState; } else { throw new IllegalMonitorStateException(); } } finally { if (failed) node.waitStatus = Node.CANCELLED; } } isOnSyncQueue 判断是否在同步队列中\nfinal boolean isOnSyncQueue(Node node) { if (node.waitStatus == Node.CONDITION || node.prev == null) return false; if (node.next != null) // If has successor, it must be on queue return true; // 从后向前遍历 return findNodeFromTail(node); } private boolean findNodeFromTail(Node node) { Node t = tail; for (;;) { if (t == node) return true; if (t == null) return false; t = t.prev; } } signal 唤醒等待中的线程\npublic final void signal() { // 检查当前线程是否用持有锁 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignal(first); } private void doSignal(Node first) { do { // 修改头结点 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; // 把 node 移入同步队列 } while (!transferForSignal(first) \u0026amp;\u0026amp; (first = firstWaiter) != null); } transferForSignal 这个方法主要是把等待队列中的 node 放入同步队列\nfinal boolean transferForSignal(Node node) { // 把 node 的状态改为初始状态0 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 进入同步队列, p 是 同步队列中 node 的前驱 Node p = enq(node); int ws = p.waitStatus; // 如果前驱是 CANCEL 或 cas失败 则直接唤醒 if (ws \u0026gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; } ","date":"2021-09-11T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/condition.png","permalink":"https://yanghaoyu.xyz/b/condition-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"Condition 源码阅读"},{"content":" 操作 作用 lock 把一个变量表示为一个线程独占, 作用于主内存的变量 unlock 把一个变量从锁定状态释放, 作用于主内存的变量 read 把主内存的变量传输到工作内存, 作用于主内存的变量 load 把 read 操作的得到的变量放入工作内存的变量副本,作用于工作内存的变量 use 把一个变量的值传给执行引擎,作用于工作内存的变量 assign 把一个从执行引擎接受到的值赋给工作内存的变量 store 把一个工作内存的一个变量传送到主内存, 作用于工作内存的变量 write 把store得到的变量写入主内存, 作用于主内存的变量 JMM 还规定了如下规则:\nread/load,store/write必须成对出现 变量在工作内存中改变了必须写回主内存, 不允许丢弃assign 不允许一个线程无原因地把数据写回主内存 在工作内存中不允许使用未初始化的变量, 即在use,store之前必须assign或load 一个变量只能被一个线程lock,同一个线程可以多次lock同一个变量 (可重入) 如果对一个变量执行 lock,那么工作内存要清空这个变量的值, 在执行引擎之前使用之前, 需要重新 load或assign (这也是为什么加锁后线程安全的原因) 对一个变量没有lock,就不允许对它unlock,也不允许unlock被其他线程 lock 住的变量 unlock之前要执行store,write,把工作内存的变量写回主内存 happens-before 操作 作用 程序次序规则 一个线程内,写在前面的操作先于写在后面的操作 管程锁定规则 对于同一个锁, unlock必须先于lock volatile 规则 对一个 volatile 变量,写操作先于读操作 线程启动规则 Thread#start先于此线程的所有动作 线程终止规则 线程的所有操作先于对此线程的终止检测 线程中断规则 线程的 interrupt 方法的调用先于中断线程检测到中断事件 对象终结规则 一个对象的构造函数的结束先于finalize方法的开始 传递性 A happens-before B, B happens-before C =\u0026gt; A happens-before C ","date":"2021-09-09T00:00:00Z","permalink":"https://yanghaoyu.xyz/b/jvm-happens-before-%E8%A7%84%E5%88%99/","title":"JVM -  happens-before 规则"},{"content":"\n对象头,Monitor 在 JVM 中，对象在内存中的布局分为三块区域：\n对象头 实例数据 对齐填充 如图所示\n其中对象头是实现 synchronized 的基础,对象头分为两部分 Mark Word, Klass Pointer, Mark Word 存储对象的 hashCode、锁信息或分代年龄或 GC 标志等信息,Klass Pointer指向该类的 Class 对象\n下表是 Mark Word 的具体信息(64 位)\nsynchronized 的锁升级 在 JDK6 之后, synchronized 底层的锁有了 4 种状态 无锁,偏向锁,轻量级锁,重量级锁,每一种状态在 Mark Word 中均有记录\n每一个锁都对应一个 monitor 对象(在 HotSpot 中由 ObjectMonitor 实现的)。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如 monitor 可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。\nObjectMonitor() { _header = NULL; _count = 0; // 计数器 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; } _WaitSet :储存处于 wait 状态的线程 _EntryList:保存用于储存等待锁的线程 _owner :指向持有 ObjectMonitor 对象的线程 当多个线程尝试进入临界区时, 首先会进入_EntryList 集合, 当线程获取到对象的 monitor 后, 把 monitor 中的 _owner 指向当前线程, 同时计数器 count++ 当线程调用 wait 方法, owner 变量恢复为 NULL,count\u0026ndash;, 表明当前线程释放 monitor,随后该线程进入 _WaitSet 集合中等待 如果当前线程执行完毕也会释放 monitor\nsynchronized 的锁膨胀 synchronized 底层的锁有了 4 种状态 无锁-\u0026gt;偏向锁-\u0026gt;轻量级锁-\u0026gt;重量级锁,膨胀方向不可逆\n偏向锁 如果一个线程获得了锁，那么锁就进入偏向模式，此时 Mark Word 的结构也就变为偏向锁结构， 当该线程再次请求锁时, 只需要检查 Mark Word 的锁标记位为偏向锁和当前线程 ID 是否等于 Mark Word 的 ThreadID 如果相等, 则当前线程获取成功,如果获取不成功, 表明这不是原来的进程, 则升级为轻量级锁\n轻量级锁 加锁 当锁未被锁定,虚拟机现在线程的栈帧中创建Displaced Lock Record,用于储存锁目前线程的Mark Word, 然后虚拟机尝试使用CAS把锁对象的Mark Word指向Displaced Lock Record,然后把锁标示位改为 00,这就表示该线程拥有了这个锁. 如果 CAS 失败,那么虚拟机会检测对象的Mark Word是否指向当前线程的栈帧,如果没有则表明锁已经被其他线程抢占了(如果有两条以上的线程抢锁的话,膨胀为重量级锁)\n解锁 使用 CAS 把Mark Word替换回来,如果替换失败的话,表明其他线程在抢锁,需要在释放锁的同时唤醒被阻塞的线程\n重量级锁 重量级锁是由轻量级锁升级而来，当同一时间有多个线程竞争锁时，锁就会被升级成重量级锁，此时其申请锁带来的开销也就变大。\n锁消除 锁消除是虚拟机另外一种锁的优化，这种优化更彻底，在 JIT 编译时，对运行上下文进行扫描，去除不可能存在竞争的锁\n锁粗化 锁粗化是虚拟机对另一种极端情况的优化处理，通过扩大锁的范围，避免反复加锁和释放锁。\n","date":"2021-09-09T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/object-monitor.png","permalink":"https://yanghaoyu.xyz/b/jvm-synchronized-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/","title":"JVM - synchronized 实现原理"},{"content":"\nstatic final class Node { static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; // 因为某些原因(超时,中断), 节点被设置为取消状态，取消的节点是不会在竞争许可的，并且这个状态不会变为其他状态； static final int CANCELLED = 1; // 表明后继节点处于阻塞状态，当前节点释放了许可或者被取消的时候会唤醒后继节点 static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; } 独占模式 acquire public final void acquire(int arg) { // 尝试获取许可 if (!tryAcquire(arg) \u0026amp;\u0026amp; // 获取失败的话 需要考虑添加到队列(#addWaiter)然后进入自旋状态(#acquireQueued) acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } addWaiter 这个方法就是把 线程包装成一个结点 然后加入到队列中, 首先尝试一下简单快速的添加, 如果不行则调用 #enq 采用 自旋+cas 强制添加\n// 把线程包装成 Node 添加到 队尾 private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; // 如果尾结点为 null ,表明是空队列 进入 #enq 初始化头结点, 否则 尝试一下简单的快速添加结点 if (pred != null) { node.prev = pred; // 使用 cas 设置 tail 如果 cas 失败, 则进入 #enq 使用 自旋+cas 的策略强制添加到队尾 if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 强制添加 enq(node); return node; } private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize // 初始化头结点 // 然后继续循环 进入 else 分支 if (compareAndSetHead(new Node())) tail = head; } else { // 添加到队尾 // 注意这里指针的修改顺序 // ① 先把node的前驱改为尾结点 node.prev = t; // ② 再把tail指向node if (compareAndSetTail(t, node)) { // ③ 最后把原来的尾结点的后继改为node (这也是#unparkSuccessor为什么要从尾结点向前遍历的原因) t.next = node; return t; } } } } acquireQueued acquireQueued 根据一定的规则控制线程阻塞或者自旋, 直到获取许可为止, 返回有没有中断过.\nfinal boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 获取前驱结点 final Node p = node.predecessor(); // 如果前驱是 head, 尝试获取许可, // 如果不是就表明 node 前面排队的 线程还有很多 不必尝试获取许可 if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; // 返回该线程是否打断过 return interrupted; } // 如果没有获取成功, 根据 #shouldParkAfterFailedAcquire 的返回值来决定是 阻塞线程还是自旋获取许可 if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) { interrupted = true; } } } finally { if (failed) { cancelAcquire(node); } } } private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; // 前一个结点如果是 SIGNAL 表明 当前线程可以中断 if (ws == Node.SIGNAL) return true; if (ws \u0026gt; 0) { // 如果前一个结点被取消, 则需要把前面所有被取消的结点都从队列中删除, 直到遇到第一个没有被取消的结点 // CANCELLED -\u0026gt; SIGNAL -\u0026gt; CANCELLED -\u0026gt; CANCELLED -\u0026gt; (pred) CANCELLED -\u0026gt; node // 变为: // CANCELLED -\u0026gt; SIGNAL -\u0026gt; node do { node.prev = pred = pred.prev; } while (pred.waitStatus \u0026gt; 0); // 重新链接 pred.next = node; } else { // 把线程设置为 SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } release 这个方法首先尝试释放许可, 释放成功则 唤醒后继结点\npublic final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) // 唤醒后继结点 unparkSuccessor(h); // 唤醒成功 return true; } // 唤醒失败 return false; } unparkSuccessor 唤醒 node 后面阻塞的后继结点, 如果 node.next 已经被取消 那么从后向前遍历找到第一个未被的结点\nprivate void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 重置状态码 if (ws \u0026lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; // 如果 s 为 null 或者已经被取消 if (s == null || s.waitStatus \u0026gt; 0) { s = null; // 从尾结点向前遍历 for (Node t = tail; t != null \u0026amp;\u0026amp; t != node; t = t.prev) //如果没有被取消, 把 t 赋值给 s if (t.waitStatus \u0026lt;= 0) s = t; } if (s != null) // 唤醒 LockSupport.unpark(s.thread); } 为什么要从后向前遍历呢?\n主要还是因为在enq方法中 结点的添加的具体逻辑导致的\n先把 node 的前驱改为尾结点 再把 tail 指向 node (cas) 最后把原来的尾结点的后继改为 node (这也是#unparkSuccessor 为什么要从尾结点向前遍历的原因) 在第 2 步完成后 发生上下文切换,那么 原来的尾结点的后继指针为 null 因此从前向后遍历会抛出 NPE 如果采用从后向前遍历, 由于 node 的前驱一定指向了原来的尾结点 因此是一定可以成功的\n共享模式 acquireShared public final void acquireShared(int arg) { // 返回 \u0026gt;= 0 表示获取成功 if (tryAcquireShared(arg) \u0026lt; 0) doAcquireShared(arg); } private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // 如果前驱是 head if (p == head) { int r = tryAcquireShared(arg); // 当其 \u0026gt;= 0 时，表示能够获取到许可，就可以从自旋中退出了 if (r \u0026gt;= 0) { setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } setHeadAndPropagate setHeadAndPropagate 在 tryAcquireShared 成功后尝试唤醒后继结点强锁\n/** * 设置对头结点，然后尝试唤醒后继结点 * * @param node the node * @param propagate tryAcquireShared 返回的值 */ private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // h 记录原来的头结点 setHead(node); // propagate \u0026gt; 0 表示没有更多的资源可以获取了，不用唤醒后继结点 // h == null, (h = head) == null 都是不可能成立的，因为调用过 addWaiter 方法了 if (propagate \u0026gt; 0 || h == null || h.waitStatus \u0026lt; 0 || (h = head) == null || h.waitStatus \u0026lt; 0) { Node s = node.next; // 只有唤醒共享模式的结点 if (s == null || s.isShared()) { doReleaseShared(); } } } releaseShared public final boolean releaseShared(int arg) { // 释放许可 if (tryReleaseShared(arg)) { // 唤醒阻塞的后继结点 doReleaseShared(); return true; } return false; } private void doReleaseShared() { for (;;) { Node h = head; if (h != null \u0026amp;\u0026amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); } else if (ws == 0 \u0026amp;\u0026amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS } if (h == head) // loop if head changed break; } } ","date":"2021-08-31T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/aqs.png","permalink":"https://yanghaoyu.xyz/b/abstractqueuedsynchronizer-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"AbstractQueuedSynchronizer 源码阅读"},{"content":"\nTreeMap的属性 private final Comparator\u0026lt;? super K\u0026gt; comparator; // 外部比较器 private transient Entry\u0026lt;K, V\u0026gt; root; // 根节点 // 代表红黑树结点颜色的常量 private static final boolean RED = false; private static final boolean BLACK = true; // 当前Map中key-value对的集合 private transient EntrySet entrySet; // 当前Map中的key的集合 private transient KeySet\u0026lt;K\u0026gt; navigableKeySet; // 【逆序】Map（实质是对当前Map实例的一个【逆序】包装） private transient NavigableMap\u0026lt;K, V\u0026gt; descendingMap; // 元素数量 private transient int size = 0; // 修改次数 private transient int modCount = 0; private static final Object UNBOUNDED = new Object(); TreeMap的构造器 public TreeMap() { comparator = null; } public TreeMap(Comparator\u0026lt;? super K\u0026gt; comparator) { this.comparator = comparator; } public TreeMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { comparator = null; putAll(m); } public TreeMap(SortedMap\u0026lt;K, ? extends V\u0026gt; m) { comparator = m.comparator(); try { buildFromSorted(m.size(), m.entrySet().iterator(), null, null); } catch (java.io.IOException | ClassNotFoundException cannotHappen) { } } 添加 public V put(K key, V value) { Entry\u0026lt;K,V\u0026gt; t = root; // 第一次添加结点 if (t == null) { compare(key, key); // type (and possibly null) check root = new Entry\u0026lt;\u0026gt;(key, value, null); size = 1; modCount++; return null; } // 找到合适的插入位置 (和二叉查找树一样) // 比较结果 int cmp; // 合适插入位置的父节点 Entry\u0026lt;K,V\u0026gt; parent; // split comparator and comparable paths Comparator\u0026lt;? super K\u0026gt; cpr = comparator; // comparator没有指定, 则使用自然排序 if (cpr != null) { do { parent = t; cmp = cpr.compare(key, t.key); if (cmp \u0026lt; 0) t = t.left; else if (cmp \u0026gt; 0) t = t.right; else return t.setValue(value); } while (t != null); } else { // 使用 comparator // key 不能为 null if (key == null) throw new NullPointerException(); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Comparable\u0026lt;? super K\u0026gt; k = (Comparable\u0026lt;? super K\u0026gt;) key; do { parent = t; cmp = k.compareTo(t.key); if (cmp \u0026lt; 0) t = t.left; else if (cmp \u0026gt; 0) t = t.right; else return t.setValue(value); } while (t != null); } // 插入结点 Entry\u0026lt;K,V\u0026gt; e = new Entry\u0026lt;\u0026gt;(key, value, parent); // 如果比较结果 \u0026lt; 0 则在父节点的左边插入 e if (cmp \u0026lt; 0) parent.left = e; // 否则右边插入 e else parent.right = e; // 调整红黑树 使其平衡 fixAfterInsertion(e); size++; modCount++; return null; } get get 就是普通的二叉查找树的算法\npublic V get(Object key) { Entry\u0026lt;K,V\u0026gt; p = getEntry(key); return (p==null ? null : p.value); } final Entry\u0026lt;K,V\u0026gt; getEntry(Object key) { // Offload comparator-based version for sake of performance if (comparator != null) // 使用 comparator 查找结点 具体算法差不多 return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Comparable\u0026lt;? super K\u0026gt; k = (Comparable\u0026lt;? super K\u0026gt;) key; Entry\u0026lt;K,V\u0026gt; p = root; while (p != null) { int cmp = k.compareTo(p.key); if (cmp \u0026lt; 0) p = p.left; else if (cmp \u0026gt; 0) p = p.right; else // 找到了 return p; } // 找不到返回 null return null; } remove // 查找key对应的元素，并移除该元素 public V remove(Object key) { Entry\u0026lt;K, V\u0026gt; p = getEntry(key); if (p == null) { return null; } V oldValue = p.value; // 将元素从红黑树中移除 deleteEntry(p); return oldValue; } // 将元素从红黑树中移除 private void deleteEntry(Entry\u0026lt;K, V\u0026gt; p) { modCount++; size--; // If strictly internal, copy successor\u0026#39;s element to p and then make p point to successor. if (p.left != null \u0026amp;\u0026amp; p.right != null) { // 寻找后继结点 Entry\u0026lt;K, V\u0026gt; s = successor(p); p.key = s.key; p.value = s.value; p = s; } // p has 2 children // Start fixup at replacement node, if it exists. Entry\u0026lt;K, V\u0026gt; replacement = (p.left != null ? p.left : p.right); if (replacement != null) { // Link replacement to parent replacement.parent = p.parent; if (p.parent == null) { root = replacement; } else if (p == p.parent.left) { p.parent.left = replacement; } else { p.parent.right = replacement; } // Null out links so they are OK to use by fixAfterDeletion. p.left = p.right = p.parent = null; // Fix replacement if (p.color == BLACK) { // 调整红黑树 fixAfterDeletion(replacement); } } else if (p.parent == null) { // return if we are the only node. root = null; } else { // No children. Use self as phantom replacement and unlink. if (p.color == BLACK) { // 调整红黑树 fixAfterDeletion(p); } if (p.parent != null) { if (p == p.parent.left) { p.parent.left = null; } else if (p == p.parent.right) { p.parent.right = null; } p.parent = null; } } } fixAfterDeletion // 在删除结点之后 调整红黑树使其平衡 private void fixAfterDeletion(Entry\u0026lt;K, V\u0026gt; x) { while (x != root \u0026amp;\u0026amp; colorOf(x) == BLACK) { if (x == leftOf(parentOf(x))) { Entry\u0026lt;K, V\u0026gt; sib = rightOf(parentOf(x)); if (colorOf(sib) == RED) { setColor(sib, BLACK); setColor(parentOf(x), RED); rotateLeft(parentOf(x)); sib = rightOf(parentOf(x)); } if (colorOf(leftOf(sib)) == BLACK \u0026amp;\u0026amp; colorOf(rightOf(sib)) == BLACK) { setColor(sib, RED); x = parentOf(x); } else { if (colorOf(rightOf(sib)) == BLACK) { setColor(leftOf(sib), BLACK); setColor(sib, RED); rotateRight(sib); sib = rightOf(parentOf(x)); } setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(rightOf(sib), BLACK); rotateLeft(parentOf(x)); x = root; } } else { // symmetric Entry\u0026lt;K, V\u0026gt; sib = leftOf(parentOf(x)); if (colorOf(sib) == RED) { setColor(sib, BLACK); setColor(parentOf(x), RED); rotateRight(parentOf(x)); sib = leftOf(parentOf(x)); } if (colorOf(rightOf(sib)) == BLACK \u0026amp;\u0026amp; colorOf(leftOf(sib)) == BLACK) { setColor(sib, RED); x = parentOf(x); } else { if (colorOf(leftOf(sib)) == BLACK) { setColor(rightOf(sib), BLACK); setColor(sib, RED); rotateLeft(sib); sib = leftOf(parentOf(x)); } setColor(sib, colorOf(parentOf(x))); setColor(parentOf(x), BLACK); setColor(leftOf(sib), BLACK); rotateRight(parentOf(x)); x = root; } } } setColor(x, BLACK); } ","date":"2021-08-30T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/treemap.png","permalink":"https://yanghaoyu.xyz/b/treemap-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"TreeMap 源码阅读"},{"content":"\nHashMap.Node\u0026lt;K,V\u0026gt; LinkedHashMap.Entry\u0026lt;K,V\u0026gt; extends HashMap.Node\u0026lt;K,V\u0026gt; class TreeNode\u0026lt;K,V\u0026gt; extends LinkedHashMap.Entry\u0026lt;K,V\u0026gt; 新增的属性 // afterNodeAccess() 的开启选项 final boolean accessOrder; // 双向链表的头结点 transient LinkedHashMap.Entry\u0026lt;K, V\u0026gt; head; // 双向链表的尾结点 transient LinkedHashMap.Entry\u0026lt;K, V\u0026gt; tail; LinkedHashMap 是如何维护插入的顺序 在构造新节点时增强 newNode 和 newTreeNode 会在 putVal 中被调用, 重写这两个方法,把新的结点尾插到链表中, 保证插入顺序\nNode\u0026lt;K, V\u0026gt; newNode(int hash, K key, V value, Node\u0026lt;K, V\u0026gt; e) { LinkedHashMap.Entry\u0026lt;K, V\u0026gt; p = new LinkedHashMap.Entry\u0026lt;\u0026gt;(hash, key, value, e); // 链接到链表的末尾 linkNodeLast(p); return p; } TreeNode\u0026lt;K, V\u0026gt; newTreeNode(int hash, K key, V value, Node\u0026lt;K, V\u0026gt; next) { TreeNode\u0026lt;K, V\u0026gt; p = new TreeNode\u0026lt;\u0026gt;(hash, key, value, next); // 链接到链表的末尾 linkNodeLast(p); return p; } // 在链表末尾链接一个新节点 private void linkNodeLast(LinkedHashMap.Entry\u0026lt;K, V\u0026gt; p) { LinkedHashMap.Entry\u0026lt;K, V\u0026gt; last = tail; tail = p; if(last == null) { head = p; } else { p.before = last; last.after = p; } } 在结点类型变化时增强 // TreeNode -\u0026gt; Node Node\u0026lt;K, V\u0026gt; replacementNode(Node\u0026lt;K, V\u0026gt; p, Node\u0026lt;K, V\u0026gt; next) { LinkedHashMap.Entry\u0026lt;K, V\u0026gt; src = (LinkedHashMap.Entry\u0026lt;K, V\u0026gt;) p; LinkedHashMap.Entry\u0026lt;K, V\u0026gt; dst = new LinkedHashMap.Entry\u0026lt;\u0026gt;(src.hash, src.key,src.value, next); transferLinks(src, dst); return dst; } // Node -\u0026gt; TreeNode TreeNode\u0026lt;K, V\u0026gt; replacementTreeNode(Node\u0026lt;K, V\u0026gt; p, Node\u0026lt;K, V\u0026gt; next) { LinkedHashMap.Entry\u0026lt;K, V\u0026gt; src = (LinkedHashMap.Entry\u0026lt;K, V\u0026gt;) p; TreeNode\u0026lt;K, V\u0026gt; dst = new TreeNode\u0026lt;\u0026gt;(src.hash, src.key, src.value, next); transferLinks(src, dst); return dst; } // 替换 src ,把 dst 连到链表中 private void transferLinks(LinkedHashMap.Entry\u0026lt;K, V\u0026gt; src, LinkedHashMap.Entry\u0026lt;K,V\u0026gt; dst) { LinkedHashMap.Entry\u0026lt;K, V\u0026gt; b = dst.before = src.before; LinkedHashMap.Entry\u0026lt;K, V\u0026gt; a = dst.after = src.after; // src 的前趋的 after 指向 dst if(b == null) { head = dst; } else { b.after = dst; } // src 的后继的 before 指向 dst if(a == null) { tail = dst; } else { a.before = dst; } } 实现回调函数 // afterNodeInsertion 会在 HashMap#putVal 中回调 // 在插入新结点的同时，删除 LinkedHashMap 中最早插入的结点 void afterNodeInsertion(boolean evict) { // possibly remove eldest LinkedHashMap.Entry\u0026lt;K, V\u0026gt; first; // removeEldestEntry 默认返回 false // ps: 重写该方法可以实现 FIFO 的 Cache if(evict \u0026amp;\u0026amp; (first = head) != null \u0026amp;\u0026amp; removeEldestEntry(first)) { K key = first.key; removeNode(hash(key), key, null, false, true); } } // afterNodeRemoval 会在 HashMap#removeNode 中回调 // 结点e从 HashMap 删除之后，也要在双向链表中删除 // before \u0026lt;-\u0026gt; e(被删除的结点) \u0026lt;-\u0026gt; after // 变为 // before \u0026lt;-\u0026gt; after void afterNodeRemoval(Node\u0026lt;K, V\u0026gt; e) { // unlink LinkedHashMap.Entry\u0026lt;K, V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K, V\u0026gt;) e, b = p.before, a =p.after; p.before = p.after = null; if(b == null) { head = a; } else { b.after = a; } if(a == null) { tail = b; } else { a.before = b; } } // afterNodeAccess 在结点被访问之后回调 (putVal, get...) // 在访问e之后，如果结点e不在链表末尾，则会把它移动到末尾 void afterNodeAccess(Node\u0026lt;K, V\u0026gt; e) { // move node to last LinkedHashMap.Entry\u0026lt;K, V\u0026gt; last; // 默认关闭，accessOrder负责开启 if(accessOrder \u0026amp;\u0026amp; (last = tail) != e) { LinkedHashMap.Entry\u0026lt;K, V\u0026gt; p = (LinkedHashMap.Entry\u0026lt;K, V\u0026gt;) e, b = p.before,a = p.after; p.after = null; if(b == null) { head = a; } else { b.after = a; } if(a != null) { a.before = b; } else { last = b; } if(last == null) { head = p; } else { p.before = last; last.after = p; } tail = p; // 结构变化 修改次数 +1 ++modCount; } } 其他 重置 LinkedHashMap void reinitialize() { /* void HashMap#reinitialize() { table = null; entrySet = null; keySet = null; values = null; modCount = 0; threshold = 0; size = 0; } */ super.reinitialize(); head = tail = null; } 序列化 // 这个方法会在 HashMap#writeObject 中被调用 void internalWriteEntries(java.io.ObjectOutputStream s) throws IOException { for(LinkedHashMap.Entry\u0026lt;K, V\u0026gt; e = head; e != null; e = e.after) { s.writeObject(e.key); s.writeObject(e.value); } } ","date":"2021-08-29T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/linkedhashmap.png","permalink":"https://yanghaoyu.xyz/b/linkedhashmap-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"LinkedHashMap 源码阅读"},{"content":"\nWeakHashMap 的原理 引用类型 gc 时间 强引用 不会被回收 软引用(SoftReference) 内存不足时回收 弱引用(WeakReference) 每一次 gc 都要回收 虚引用 Unknown private final ReferenceQueue\u0026lt;Object\u0026gt; queue = new ReferenceQueue\u0026lt;\u0026gt;(); WeakHashMap.Entry private static class Entry\u0026lt;K, V\u0026gt; extends WeakReference\u0026lt;Object\u0026gt; implements Map.Entry\u0026lt;K, V\u0026gt; { // ... V value; final int hash; Entry\u0026lt;K, V\u0026gt; next; Entry(Object key, V value, ReferenceQueue\u0026lt;Object\u0026gt; queue, int hash, Entry\u0026lt;K, V\u0026gt; next) { // 把 key 作为弱引用, 在下一次 gc 时 key 将会被删除 super(key, queue); this.value = value; this.hash = hash; this.next = next; } // ... } 在 其构造器中 可以看到 Entry 把 key 作为弱引用,gc 时进行删除, 但是此时 value 并未删除\nexpungeStaleEntries函数 删除 value private void expungeStaleEntries() { Object x; // gc之后 把Entry 已经保存到 queue 中 while ((x = queue.poll()) != null) { synchronized (queue) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Entry\u0026lt;K, V\u0026gt; e = (Entry\u0026lt;K, V\u0026gt;) x; // 获取索引 int i = indexFor(e.hash, table.length); Entry\u0026lt;K, V\u0026gt; prev = table[i]; Entry\u0026lt;K, V\u0026gt; p = prev; // 遍历链表，清理value while (p != null) { Entry\u0026lt;K, V\u0026gt; next = p.next; if (p == e) { if (prev == e) { table[i] = next; } else { prev.next = next; } /* * Must not null out e.next; * stale entries may be in use by a HashIterator */ e.value = null; // Help GC size--; break; } prev = p; p = next; } } } } 在特定的方法中调用expungeStaleEntries 可以看到 expungeStaleEntries 在 size resize get中被调用\n关于 WeakHashSet 在 JDK 中没有WeakHashSet, 不过使用如下代码可以达到相同的效果\n// 使用 Collections 将其包装成一个Set Set\u0026lt;Object\u0026gt; weakHashSet = Collections.newSetFromMap(new WeakHashMap\u0026lt;Object, Boolean\u0026gt;()); 事实上, SetFromMap 也是对其做了一层包装\npublic static \u0026lt;E\u0026gt; Set\u0026lt;E\u0026gt; newSetFromMap(Map\u0026lt;E, Boolean\u0026gt; map) { return new SetFromMap\u0026lt;\u0026gt;(map); } private static class SetFromMap\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Serializable{ private static final long serialVersionUID = 2454657854757543876L; private final Map\u0026lt;E, Boolean\u0026gt; m; // The backing map private transient Set\u0026lt;E\u0026gt; s; // Its keySet SetFromMap(Map\u0026lt;E, Boolean\u0026gt; map) { if(!map.isEmpty()) { throw new IllegalArgumentException(\u0026#34;Map is non-empty\u0026#34;); } m = map; s = map.keySet(); } public boolean add(E e) { return m.put(e, Boolean.TRUE) == null; } public boolean remove(Object o) { return m.remove(o) != null; } @Override public boolean removeIf(Predicate\u0026lt;? super E\u0026gt; filter) { return s.removeIf(filter); } public boolean removeAll(Collection\u0026lt;?\u0026gt; c) { return s.removeAll(c); } public boolean retainAll(Collection\u0026lt;?\u0026gt; c) { return s.retainAll(c); } public void clear() { m.clear(); } public boolean contains(Object o) { return m.containsKey(o); } public boolean containsAll(Collection\u0026lt;?\u0026gt; c) { return s.containsAll(c); } public Object[] toArray() { return s.toArray(); } public \u0026lt;T\u0026gt; T[] toArray(T[] a) { return s.toArray(a); } // Override default methods in Collection @Override public void forEach(Consumer\u0026lt;? super E\u0026gt; action) { s.forEach(action); } public Iterator\u0026lt;E\u0026gt; iterator() { return s.iterator(); } @Override public Spliterator\u0026lt;E\u0026gt; spliterator() { return s.spliterator(); } @Override public Stream\u0026lt;E\u0026gt; stream() { return s.stream(); } @Override public Stream\u0026lt;E\u0026gt; parallelStream() { return s.parallelStream(); } public int size() { return m.size(); } public boolean isEmpty() { return m.isEmpty(); } public boolean equals(Object o) { return o == this || s.equals(o); } public int hashCode() { return s.hashCode(); } public String toString() { return s.toString(); } private void readObject(java.io.ObjectInputStream stream) throws IOException, ClassNotFoundException { stream.defaultReadObject(); s = m.keySet(); } } ","date":"2021-08-29T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/weakhashmap.png","permalink":"https://yanghaoyu.xyz/b/weakhashmap-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"WeakHashMap 源码阅读"},{"content":" HashSet 的具体实现 public class HashSet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, Serializable { static final long serialVersionUID = -5024744406713321676L; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); private transient HashMap\u0026lt;E, Object\u0026gt; map; public HashSet() { map = new HashMap\u0026lt;\u0026gt;(); } public HashSet(int initialCapacity) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity); } public HashSet(int initialCapacity, float loadFactor) { map = new HashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } public HashSet(Collection\u0026lt;? extends E\u0026gt; c) { map = new HashMap\u0026lt;\u0026gt;(Math.max((int) (c.size() / .75f) + 1, 16)); addAll(c); } HashSet(int initialCapacity, float loadFactor, boolean dummy) { map = new LinkedHashMap\u0026lt;\u0026gt;(initialCapacity, loadFactor); } // 添加 public boolean add(E e) { return map.put(e, PRESENT) == null; } // 删除 public boolean remove(Object o) { return map.remove(o) == PRESENT; } // 清空 public void clear() { map.clear(); } // 包含 public boolean contains(Object o) { return map.containsKey(o); } public Iterator\u0026lt;E\u0026gt; iterator() { return map.keySet().iterator(); } public Spliterator\u0026lt;E\u0026gt; spliterator() { return new HashMap.KeySpliterator\u0026lt;\u0026gt;(map, 0, -1, 0, 0); } public int size() { return map.size(); } public boolean isEmpty() { return map.isEmpty(); } // 序列化 private void writeObject(ObjectOutputStream s) throws IOException { // Write out any hidden serialization magic s.defaultWriteObject(); // Write out HashMap capacity and load factor s.writeInt(map.capacity()); s.writeFloat(map.loadFactor()); // Write out size s.writeInt(map.size()); // Write out all elements in the proper order. for(E e : map.keySet()) s.writeObject(e); } /** * Reconstitute the {@code HashSet} instance from a stream (that is, * deserialize it). */ private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException { // Read in any hidden serialization magic s.defaultReadObject(); // Read capacity and verify non-negative. int capacity = s.readInt(); if(capacity\u0026lt;0) { throw new InvalidObjectException(\u0026#34;Illegal capacity: \u0026#34; + capacity); } // Read load factor and verify positive and non NaN. float loadFactor = s.readFloat(); if(loadFactor\u0026lt;=0 || Float.isNaN(loadFactor)) { throw new InvalidObjectException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); } // Read size and verify non-negative. int size = s.readInt(); if(size\u0026lt;0) { throw new InvalidObjectException(\u0026#34;Illegal size: \u0026#34; + size); } // Set the capacity according to the size and load factor ensuring that // the HashMap is at least 25% full but clamping to maximum capacity. capacity = (int) Math.min(size * Math.min(1 / loadFactor, 4.0f), HashMap.MAXIMUM_CAPACITY); // Constructing the backing map will lazily create an array when the first element is // added, so check it before construction. Call HashMap.tableSizeFor to compute the // actual allocation size. Check Map.Entry[].class since it\u0026#39;s the nearest public type to // what is actually created. SharedSecrets.getJavaObjectInputStreamAccess().checkArray(s, Map.Entry[].class, HashMap.tableSizeFor(capacity)); // Create backing HashMap map = (this instanceof LinkedHashSet ? new LinkedHashMap\u0026lt;\u0026gt;(capacity, loadFactor) : new HashMap\u0026lt;\u0026gt;(capacity, loadFactor)); // Read in all elements in the proper order. for(int i = 0; i\u0026lt;size; i++) { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) E e = (E) s.readObject(); map.put(e, PRESENT); } } ` @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public Object clone() { try { HashSet\u0026lt;E\u0026gt; newSet = (HashSet\u0026lt;E\u0026gt;) super.clone(); newSet.map = (HashMap\u0026lt;E, Object\u0026gt;) map.clone(); return newSet; } catch(CloneNotSupportedException e) { throw new InternalError(e); } } } ","date":"2021-08-28T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/blog-hero-jdk-hashset.webp","permalink":"https://yanghaoyu.xyz/b/hashset-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"HashSet 源码阅读"},{"content":" HashMap的属性 // 哈希数组最大容量 static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; // 哈希数组默认容量 static final int DEFAULT_INITIAL_CAPACITY = 16; // 默认装载因子 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 树化阈值, 某个哈希槽上的元素数量增加到此值后，这些元素进入波动期，即将从链表转换为红黑树 static final int TREEIFY_THRESHOLD = 8; // 最小树化容量, 哈希数组的容量满足此值，且满足TREEIFY_THRESHOLD的要求时，将链表转换为红黑树 static final int MIN_TREEIFY_CAPACITY = 64; // untreeify的阈值, 红黑树上的元素数量减少到此值时，将红黑树转换为链表 static final int UNTREEIFY_THRESHOLD = 6; // 哈希数组 transient Node\u0026lt;K, V\u0026gt;[] table; // HashMap中的元素数量 transient int size; // 装载因子 final float loadFactor; // HashMap扩容阈值 // threshold = length * Load factor int threshold; // entry集合 transient Set\u0026lt;Map.Entry\u0026lt;K, V\u0026gt;\u0026gt; entrySet; // 修改次数 记录HashMap内部结构的变化 用于实现 fail-fast 机制 transient int modCount; 构造器 // 默认生成一个 容量为16, 装载因子为0.75的 HashMap public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } // 生成一个哈希数组容量为 initialCapacity，装载因子为0.75的HashMap public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } // 生成一个哈希数组容量为 initialCapacity，装载因子为 loadFactor 的H ashMap public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); } if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) { initialCapacity = MAXIMUM_CAPACITY; } if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) { throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); } // 初始化装载因子 this.loadFactor = loadFactor; // 用初始容量信息来初始化HashMap扩容阈值，该阈值后续将作为初始化哈希数组的容量依据 this.threshold = tableSizeFor(initialCapacity); } // 使用指定的HashMap中的元素来初始化一个新的HashMap public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; // 将指定HashMap中的元素存入到当前HashMap（允许覆盖） putMapEntries(m, false); } 确定哈希树组的索引 首先调用 key#hashCode得到哈希码,然后把哈希码和其高 16 位进行异或运算(为了减少哈希碰撞),得到最终的哈希值 h, 然后调用indexFor,得到最终的索引\nstatic final int hash(Object key) { int h; return key == null ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } // 计算索引, jdk1.8没有这个方法, 但是实现原理一样的 static int indexFor(int h, int length) { // 当 length 是2的 n 次方时,等价于 h % length return h \u0026amp; (length-1); } putVal final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // 当前哈希数组 Node\u0026lt;K, V\u0026gt;[] tab; // 待插入元素应当插入的位置 Node\u0026lt;K, V\u0026gt; p; int n, i; // 如果哈希数组未初始化，或者容量为0，则初始化 if ((tab = table) == null || (n = tab.length) == 0) { // 对哈希数组扩容，返回新的哈希数组 tab = resize();` n = tab.length; } // 获得 key 所对应的哈希槽的结点 p = tab[i = (n - 1) \u0026amp; hash]; // 如果哈希槽为空，则直接放进去即可 if (p == null) { tab[i] = newNode(hash, key, value, null); } else { // 发生哈希碰撞 使用 拉链法 链接元素 Node\u0026lt;K, V\u0026gt; e; K k; // 判断首个元素 if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { e = p; } else if (p instanceof TreeNode) { // 如果是红黑树结点，调用红黑树的插入方法 e = ((TreeNode\u0026lt;K, V\u0026gt;) p).putTreeVal(this, tab, hash, key, value); } else { // 链表结构 // 遍历（ binCount 统计的是遍历过的元素数量） for (int binCount = 0; ; ++binCount) { // 遍历到链表末尾, 如果没有还找到同位元素, 则插入 if ((e = p.next) == null) { // 插入 p.next = newNode(hash, key, value, null); // 插入之后, 如果哈希槽上的元素数量增加到 8 后，尝试转为红黑树 if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) { // -1 for 1st treeifyBin(tab, hash); } break; } // 如果找到同位元素, 直接退出循环 if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { break; } p = e; } } // 如果存在同位元素 if (e != null) { // existing mapping for key V oldValue = e.value; // 判断是否需要修改 if (!onlyIfAbsent || oldValue == null) { // update oldValue e.value = value; } // 回调函数 默认空实现 afterNodeAccess(e); return oldValue; } } ++modCount; // 如果哈希数组的容量超过阈值，则扩容 if (++size \u0026gt; threshold) { resize(); } // 回调函数 默认空实现 afterNodeInsertion(evict); // 如果插入的是新的元素，在这里返回 null return null; } 链表的树化 final void treeifyBin(Node\u0026lt;K, V\u0026gt;[] tab, int hash) { int n; // 哈希数组的容量 \u0026lt; MIN_TREEIFY_CAPACITY 不能转为红黑树 直接扩容 if (tab == null || (n = tab.length) \u0026lt; MIN_TREEIFY_CAPACITY) { // 扩容 resize(); } else { // 转换为红黑树 int index = (n - 1) \u0026amp; hash; Node\u0026lt;K, V\u0026gt; e = tab[index]; if (e != null) { // hd is \u0026#39;head\u0026#39;, tl is \u0026#39;tail\u0026#39; TreeNode\u0026lt;K, V\u0026gt; hd = null, tl = null; // 遍历链表 把链表的结点改为红黑树结点(此时还未生成树结构,还是链表结构) do { // 将元素e从链表结点转换为红黑树结点 TreeNode\u0026lt;K, V\u0026gt; p = replacementTreeNode(e, null); if (tl == null) { hd = p; } else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); // 树化红黑树结点 生成树结构 if ((tab[index] = hd) != null) { hd.treeify(tab); } } } } 扩容机制 resize 初始化哈希数组，或者对哈希数组扩容，返回新的哈希数组 扩容之后, 需要再次对容器内的元素进行哈希, 确定元素在新的空间的具体位置\n注：哈希数组的容量跟 HashMap 存放的元素数量没有必然联系 哈希数组只存放一系列同位元素（在 HashMap 中占据相同位置的元素）中最早进来的那个\nfinal Node\u0026lt;K, V\u0026gt;[] resize() { Node\u0026lt;K, V\u0026gt;[] oldTab = table; // 旧容量 int oldCap = (oldTab == null) ? 0 : oldTab.length; // 旧阈值 int oldThr = threshold; // 新容量 int newCap; // 新阈值 int newThr = 0; // 如果已经初始化 if (oldCap \u0026gt; 0) { // 超过最大值 if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { // 将HashMap的阈值更新为允许的最大值 threshold = Integer.MAX_VALUE; return oldTab; } else { // 哈希表数组容量加倍 newCap = oldCap \u0026lt;\u0026lt; 1; // 如果容量没有达到上限，则将阈值也加倍 if (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) { newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } } } else { // 如果哈希数组还未初始化 // 在实例化时已经指定 initialCapacity, 则直接使用初始化容量 if (oldThr \u0026gt; 0) { newCap = oldThr; } else { // 如果没有指定初始容量，则使用默认的容量与阈值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int) (DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } } // 计算 threshold // 如果哈希数组容量翻倍之后超出最大容量, 则要把 threshold 改为 Integer.MAX_VALUE if (newThr == 0) { float ft = (float) newCap * loadFactor; newThr = newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float) MAXIMUM_CAPACITY ? (int) ft // 针对第二种情况，将阈值更新为初始容量*装载因子 : Integer.MAX_VALUE; // 针对第一种情况，将阈值更新为最大值 } // 更新阈值 threshold = newThr; // 开辟内存空间 @SuppressWarnings({\u0026#34;rawtypes\u0026#34;, \u0026#34;unchecked\u0026#34;}) Node\u0026lt;K, V\u0026gt;[] newTab = (Node\u0026lt;K, V\u0026gt;[]) new Node[newCap]; table = newTab; // 开始把原数组拷贝到新数组 并进行再散列 if (oldTab != null) { // 遍历哈希数组 for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K, V\u0026gt; e = oldTab[j]; // 如果当前哈希槽上存在元素 if (e != null) { // 置空该哈希槽 oldTab[j] = null; // 如果该哈希槽上只有一个元素 if (e.next == null) { // 重新哈希 确定在新数组的位置 newTab[e.hash \u0026amp; (newCap - 1)] = e; // 如果该哈希槽上链接了不止一个元素，且该元素是TreeNode类型 } else if (e instanceof TreeNode) { // 红黑树结构 ((TreeNode\u0026lt;K, V\u0026gt;) e).split(this, newTab, j, oldCap); } else { // 链表结构 Node\u0026lt;K, V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K, V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K, V\u0026gt; next; // 将原有的结点分成两拨, 放入不同的哈希槽 // 这是 HashMap 设计的一个精妙之处 do { next = e.next; if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) { loHead = e; } else { loTail.next = e; } loTail = e; } else { if (hiTail == null) { hiHead = e; } else { hiTail.next = e; } hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 将哈希槽的链表拷贝到新的哈希数组,是 HashMap 设计的一个精妙之处\nHashMap 的容量都是 2^n\nvalues.length = 16 // hash hash(key1) = 10101 hash(key2) = 00101 // 索引 index(key1) = 10101 \u0026amp; 1111 = 00101 index(key2) = 00101 \u0026amp; 1111 = 00101 产生哈希碰撞 扩容后\nvalues.length = 32 // hash hash(key1) = 10101 hash(key2) = 00101 // 索引 index(key1) = 10101 \u0026amp; 11111 = 10101 index(key2) = 00101 \u0026amp; 11111 = 00101 可以看到在扩容之后 原来产生哈希碰撞的两个 key 已经不再碰撞了\n而实际上, 扩容之后的索引位置 不过是将 key 的哈希码的更高的一位纳入了考虑范围 10101和00101 仅在 最高位不同 据此 在 哈希树组拷贝的过程中 原来的链表分成两部分\n判断 e.hash \u0026amp; oldCap 该表达式是否为 0 (这就直接判断了更高一位是否为 0)\n如果为 0, 放到 loHead 这个链表中 否则放到 hiHead 链表中 之后只需把loHead和hiHead按照新的索引放到哈希树组正确的位置即可\n而新的索引可以这样确定:\nindex(loHead) 没变 index(hiHead)最高位为 1,因此要在原来索引的基础上加上 oldCap,才是新的索引 getNode // 根据 hash 和 key 确定到目标结点 如果不存在 返回 null final Node\u0026lt;K, V\u0026gt; getNode(int hash, Object key) { Node\u0026lt;K, V\u0026gt;[] tab; Node\u0026lt;K, V\u0026gt; first, e; int n; K k; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (first = tab[(n - 1) \u0026amp; hash]) != null) { // 判断第一个结点 if (first.hash == hash \u0026amp;\u0026amp; // always check first node ((k = first.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { return first; } // 如果这个哈希槽上存在 \u0026gt;= 1 个结点 if ((e = first.next) != null) { // 红黑树结构 if (first instanceof TreeNode) { return ((TreeNode\u0026lt;K, V\u0026gt;) first).getTreeNode(hash, key); } // 链表结构 遍历下去即可 do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { return e; } } while ((e = e.next) != null); } } return null; } removeNode final Node\u0026lt;K, V\u0026gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node\u0026lt;K, V\u0026gt;[] tab; Node\u0026lt;K, V\u0026gt; p; int n, index; if ((tab = table) != null \u0026amp;\u0026amp; (n = tab.length) \u0026gt; 0 \u0026amp;\u0026amp; (p = tab[index = (n - 1) \u0026amp; hash]) != null) { Node\u0026lt;K, V\u0026gt; node = null, e; K k; V v; // 根据给定的 key 和 hash 获取到目标结点 if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = p; } else if ((e = p.next) != null) { if (p instanceof TreeNode) { // 红黑树 node = ((TreeNode\u0026lt;K, V\u0026gt;) p).getTreeNode(hash, key); } else { // 链表 do { if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } // 移除元素 // 如果 matchValue == true 那么还要保证value也相同 if (node != null \u0026amp;\u0026amp; (!matchValue || (v = node.value) == value || (value != null \u0026amp;\u0026amp; value.equals(v)))) { if (node instanceof TreeNode) { ((TreeNode\u0026lt;K, V\u0026gt;) node).removeTreeNode(this, tab, movable); } else if (node == p) { tab[index] = node.next; } else { p.next = node.next; } ++modCount; --size; // 回调函数 默认空实现 afterNodeRemoval(node); return node; } } return null; } ","date":"2021-08-25T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/hashmap.png","permalink":"https://yanghaoyu.xyz/b/hashmap-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"HashMap 源码阅读"},{"content":" 基本属性 // Unsafe 实例 用于操作底层 private static final jdk.internal.misc.Unsafe U = jdk.internal.misc.Unsafe.getUnsafe(); // value的偏移地址 private static final long VALUE = U.objectFieldOffset(AtomicInteger.class, \u0026#34;value\u0026#34;); private volatile int value; 使用 CAS 实现原子操作 public final int incrementAndGet() { return U.getAndAddInt(this, VALUE, 1) + 1; } getAndAddInt 首先会获取 v 的值,然后使用 CAS 修改 v,如果修改失败,则表明 v 被其他的线程修改, 则继续获取 v,继续使用 CAS 修改,直到修改成功,否则一直自旋\n@HotSpotIntrinsicCandidate public final int getAndAddInt(Object o, long offset, int delta) { int v; do { // 获取对象o中offset地址处对应的int型字段的值， // 支持volatile语义 v = getIntVolatile(o, offset); // 拿期望值v与对象o的offset地址处的当前值比较， // 如果两个值相等，将当前值更新为 v + delta，并 // 返回true，否则返回false } while (!weakCompareAndSetInt(o, offset, v, v + delta)); return v; } // 拿期望值expected与对象o的offset地址处的当前值比较，如果两个值相等，将当前值更新为x @HotSpotIntrinsicCandidate public final boolean weakCompareAndSetInt(Object o, long offset, int expected, int x) { return compareAndSetInt(o, offset, expected, x); } @HotSpotIntrinsicCandidate public final native boolean compareAndSetInt(Object o, long offset, int expected, int x); compareAndSetInt 的实现 UNSAFE_ENTRY( jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x) ) UnsafeWrapper(\u0026#34;Unsafe_CompareAndSwapInt\u0026#34;); oop p = JNIHandles::resolve(obj); jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); // 使用 cmpxchg 实现 CAS return (jint)(Atomic::cmpxchg(x, addr, e)) == e; UNSAFE_END Atomic::cmpxchg 在 Linux + x86 的实现 在 Linux 平台下，主要使用 cmpxchgl 实现，这个汇编指令并不是原子的\n首先使用 os::is_MP() 判断是否是 multiprocessor(多核处理器)\nLOCK_IF_MP 是一个宏，它会根据 CPU 是否是多核，来决定是否为 cmpxchgl 添加上 lock 前缀\n同时可以注意到这条指令已经加上 volatile，这会告知 C 编译器不要对代码进行优化\n// Adding a lock prefix to an instruction on MP machine #define LOCK_IF_MP(mp) \u0026#34;cmp $0, \u0026#34; #mp \u0026#34;; je 1f; lock; 1: \u0026#34; inline jint Atomic::cmpxchg(jint exchange_value, volatile jint *dest, jint compare_value) { int mp = os::is_MP(); __asm__ volatile(LOCK_IF_MP(%4) \u0026#34;cmpxchgl %1,(%3)\u0026#34; : \u0026#34;=a\u0026#34;(exchange_value) : \u0026#34;r\u0026#34;(exchange_value), \u0026#34;a\u0026#34;(compare_value), \u0026#34;r\u0026#34;(dest), \u0026#34;r\u0026#34;(mp) : \u0026#34;cc\u0026#34;, \u0026#34;memory\u0026#34;); return exchange_value; } 在 Windows 的实现 #define LOCK_IF_MP(mp) __asm cmp mp, 0 \\ __asm je L0 \\ __asm _emit 0xF0 \\ __asm L0: inline jint Atomic::cmpxchg (jint exchange_value, volatile jint *dest, jint compare_value) { // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm { mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx } } lock 前缀 可以确保后续指令执行的原子性。 使用 总线锁定 CPU 在总线上输出LOCK#信号,暂时阻塞其他 CPU 通过总线对内存进行操作,这个开销非常大的,这在 Pentium 及之前的处理器中被采用 使用 缓存锁定 缓存锁定是某个 CPU 对缓存数据进行更改时，会通知缓存了该数据的 CPU 抛弃缓存的数据或者从内存重新读取。 但是如果操作的数在多个缓存行内,则直接采用总线缓存 禁止该指令与前面和后面的读写指令重排序。 把写缓冲区的所有数据刷新到内存中。 上面的第 2 点和第 3 点所具有的内存屏障效果，保证了 CAS 同时具有 volatile 读和 volatile 写的内存语义。 ","date":"2021-08-06T00:00:00Z","permalink":"https://yanghaoyu.xyz/b/atomicinteger-cas-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"AtomicInteger \u0026 CAS 源码阅读"},{"content":"\nCopyOnWriteArrayList实现了List接口,允许随机访问\npublic class CopyOnWriteArrayList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAccess, Cloneable, java.io.Serializable 基本属性 lock 一把锁,用于实现写-写互斥 array 存放数据的数组 /** * The lock protecting all mutators. (We have a mild preference * for builtin monitors over ReentrantLock when either will do.) */ final transient Object lock = new Object(); /** The array, accessed only via getArray/setArray. */ private transient volatile Object[] array; 构造器 public CopyOnWriteArrayList() { setArray(new Object[0]); } public CopyOnWriteArrayList(Collection\u0026lt;? extends E\u0026gt; c) { Object[] es; if (c.getClass() == CopyOnWriteArrayList.class) es = ((CopyOnWriteArrayList\u0026lt;?\u0026gt;)c).getArray(); else { es = c.toArray(); // defend against c.toArray (incorrectly) not returning Object[] // (see e.g. https://bugs.openjdk.java.net/browse/JDK-6260652) // 如果不是Object[] 则转换一下 // 这是JDK的设计缺陷 c.toArray不一定返回Object[], 比如 Arrays.asList 返回的是T[] if (es.getClass() != Object[].class) es = Arrays.copyOf(es, es.length, Object[].class); } setArray(es); } public CopyOnWriteArrayList(E[] toCopyIn) { // 把数组拷贝一份 setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class)); } final void setArray(Object[] a) { array = a; } 使用写时复制实现读写分离 1. add public boolean add(E e) { synchronized (lock) { Object[] es = getArray(); int len = es.length; es = Arrays.copyOf(es, len + 1); es[len] = e; setArray(es); return true; } } 可以看到 add 操作会先复制一个数组, 并在该数组上进行操作, 而原来的数组不受影响, 其他线程来进行读操作,不会引发线程安全问题, 当写操作完毕之后, 会把原来的数组指针指向新的数组, 实现了数据的更新。所以保证了数据的最终一致性, 没法保证数组的实时一致性。\n2. 迭代器 在每次或者迭代器时, COWIterator 都会保存原来数组的指针为 snapshot, 然后对 snapshot 进行遍历操作,因为写操作都是在拷贝出来的数组上进行的,所以 snapshot,可以一边遍历一边修改,是线程安全的,同时 COWIterator 是不允许 add,set ,remove这些写操作的。\nstatic final class COWIterator\u0026lt;E\u0026gt; implements ListIterator\u0026lt;E\u0026gt; { /** Snapshot of the array */ private final Object[] snapshot; /** Index of element to be returned by subsequent call to next. */ private int cursor; COWIterator(Object[] es, int initialCursor) { cursor = initialCursor; snapshot = es; } public boolean hasNext() { return cursor \u0026lt; snapshot.length; } public boolean hasPrevious() { return cursor \u0026gt; 0; } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E next() { if (!hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E previous() { if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; } public int nextIndex() { return cursor; } public int previousIndex() { return cursor - 1; } public void remove() { throw new UnsupportedOperationException(); } public void set(E e) { throw new UnsupportedOperationException(); } public void add(E e) { throw new UnsupportedOperationException(); } @Override public void forEachRemaining(Consumer\u0026lt;? super E\u0026gt; action) { Objects.requireNonNull(action); final int size = snapshot.length; int i = cursor; cursor = size; for (; i \u0026lt; size; i++) action.accept(elementAt(snapshot, i)); } } CopyOnWriteArrayList 比Vector效率高,但是占用空间大,有可能导致 gc,甚至是 Stop the world\n","date":"2021-07-31T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/copyonwritearraylist.png","permalink":"https://yanghaoyu.xyz/b/copyonwritearraylist-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"CopyOnWriteArrayList 源码阅读"},{"content":"\n基本属性 // 默认的容量 private static final int DEFAULT_INITIAL_CAPACITY = 11; transient Object[] queue; int size; // 自定义比较器,如果为null,则使用默认的比较器,所以必须实现Comparable或者传入比较器,否则会抛出异常! private final Comparator\u0026lt;? super E\u0026gt; comparator; transient int modCount; 构造器 public PriorityQueue(int initialCapacity,Comparator\u0026lt;? super E\u0026gt; comparator) { if (initialCapacity \u0026lt; 1) throw new IllegalArgumentException(); this.queue = new Object[initialCapacity]; this.comparator = comparator; } public PriorityQueue() { this(DEFAULT_INITIAL_CAPACITY, null); } public PriorityQueue(int initialCapacity) { this(initialCapacity, null); } public PriorityQueue(Comparator\u0026lt;? super E\u0026gt; comparator) { this(DEFAULT_INITIAL_CAPACITY, comparator); } 关键方法 1. add ，offer add 和offer语义是一样的\npublic boolean offer(E e) { if (e == null) throw new NullPointerException(); modCount++; int i = size; if (i \u0026gt;= queue.length) // 自动扩容 grow(i + 1); // 上滤 siftUp(i, e); size = i + 1; return true; } 2. siftUp :::tip 上滤,向堆中添加一个元素 x,直接把它放在数组末尾,这时堆的性质已经被破坏,那么我们需要通过 siftUp 维持堆的性质,根据完全二叉树的性质,计算出它父节点的索引 parent,逐层向上比较,直到 x \u0026gt;= queue[parent]位置 :::\nprivate void siftUp(int k, E x) { if (comparator != null) siftUpUsingComparator(k, x, queue, comparator); else siftUpComparable(k, x, queue); } private static \u0026lt;T\u0026gt; void siftUpComparable(int k, T x, Object[] es) { Comparable\u0026lt;? super T\u0026gt; key = (Comparable\u0026lt;? super T\u0026gt;) x; while (k \u0026gt; 0) { int parent = (k - 1) \u0026gt;\u0026gt;\u0026gt; 1; Object e = es[parent]; // 比较一下 判断是否终止 if (key.compareTo((T) e) \u0026gt;= 0) break; // 向上迭代 es[k] = e; k = parent; } es[k] = key; } 3. remove 和 poll remove 和poll语义是一样的,不同在于失败的时候remove抛出异常,poll会返回null :::tip 下滤 在删除头结点时,首先把最后一个结点赋值给头结点,然后逐层向下比较,找到合适的位置 :::\npublic E poll() { final Object[] es; final E result; if ((result = (E) ((es = queue)[0])) != null) { modCount++; final int n; final E x = (E) es[(n = --size)]; es[n] = null; if (n \u0026gt; 0) { final Comparator\u0026lt;? super E\u0026gt; cmp; if ((cmp = comparator) == null) // 下滤 siftDownComparable(0, x, es, n); else siftDownUsingComparator(0, x, es, n, cmp); } } return result; } private static \u0026lt;T\u0026gt; void siftDownComparable(int k, T x, Object[] es, int n) { // assert n \u0026gt; 0; Comparable\u0026lt;? super T\u0026gt; key = (Comparable\u0026lt;? super T\u0026gt;)x; int half = n \u0026gt;\u0026gt;\u0026gt; 1; while (k \u0026lt; half) { int child = (k \u0026lt;\u0026lt; 1) + 1; // assume left child is least Object c = es[child]; int right = child + 1; if (right \u0026lt; n \u0026amp;\u0026amp; ((Comparable\u0026lt;? super T\u0026gt;) c).compareTo((T) es[right]) \u0026gt; 0) { c = es[child = right]; } if (key.compareTo((T) c) \u0026lt;= 0) { break; } es[k] = c; k = child; } es[k] = key; } ","date":"2021-07-29T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/heap.png","permalink":"https://yanghaoyu.xyz/b/priorityqueue-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"PriorityQueue 源码阅读"},{"content":"\n相关属性 /** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */ // 用于存储数据的数组, elementData.length 表示容量 transient Object[] elementData; // non-private to simplify nested class access /** * The size of the ArrayList (the number of elements it contains). */ // 当前元素的数量 private int size; 静态属性 // 序列化版本号 private static final long serialVersionUID = 8683452581122892189L; /** * Default initial capacity. */ // 默认初始化容量 new ArrayList() 将会采用这个容量 private static final int DEFAULT_CAPACITY = 10; /** * Shared empty array instance used for empty instances. */ // 空数组,通过new ArrayList(0)产生的ArrayList中的elementDate会指向这个字段 private static final Object[] EMPTY_ELEMENTDATA = {}; /** * Shared empty array instance used for default sized empty instances. We * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when * first element is added. */ // 默认容量空数组,通过new ArrayList()产生的ArrayList中的elementDate会指向这个字段 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; // ▼ 为什么要使用两个默认的空数组? ▼ // A: 使用两个空数组主要是为了区分首次扩容, 用来指示该ArrayList是通过new ArrayList()还是new ArrayList(0)产生, // 随着数组中元素的增加, grow会根据elementData的初始指向来决定怎样扩容 /* ① 使用 new ArrayList() 构造 在未添加数据时 elementData 会指向 DEFAULTCAPACITY_EMPTY_ELEMENTDATA 随着数组的加入, 容量序列是 10\t15\t22\t33\t49\t73\t109\t... ... ② 使用 new ArrayList(0) 构造 在未添加数据时 elementData 会指向 EMPTY_ELEMENTDATA 随着数组的加入, 容量序列是 1\t2\t3\t4\t6\t9\t13\t19\t28\t42\t63\t94\t141\t... ... ③ 使用 new ArrayList(int) 构造 会直接new出数组, 不会指向上述两个数组 */ /** * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit * * 最大容量 * 为什么要 -8 ? * 某些JVM会把对象头所占的空间预留在数组中,所以减少一些容量确保内存不会溢出 * 但实际上这个参数并不是那么重要 在hugeCapacity这个方法中,可以将数组容量扩展成 Integer.MAX_VALUE */ private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 构造器 无参构造器 public ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } 有参构造器 public ArrayList(int initialCapacity) { if (initialCapacity \u0026gt; 0) { // 默认容量 \u0026gt; 0 直接new出数组 this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { // 默认容量 == 0 指向静态字段 this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34; + initialCapacity); } } public ArrayList(Collection\u0026lt;? extends E\u0026gt; c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) // 拷贝过来 elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; } } 主要方法 1.add public boolean add(E e) { // 确保容量足够 ensureCapacityInternal(size + 1); // Increments modCount!! // 添加 elementData[size++] = e; return true; } 2.ensureCapacityInternal private void ensureCapacityInternal(int minCapacity) { ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); } 3.calculateCapacity private static int calculateCapacity(Object[] elementData, int minCapacity) { // 使用 无参构造 new出的ArrayList 在第一次添加时把容量改为 DEFAULT_CAPACITY 即10 // new ArrayList() 和 new ArrayList(0) 的区别 就是在此体现出来的 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { return Math.max(DEFAULT_CAPACITY, minCapacity); } return minCapacity; } 4.ensureExplicitCapacity 根据条件判断是否扩容\nprivate void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length \u0026gt; 0) // 扩容 grow(minCapacity); } 5.grow 扩容函数, 把原来数组的长度变为 1.5 倍\n/** * 扩容 * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */ private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; // 扩大成原来的1.5倍 int newCapacity = oldCapacity + (oldCapacity \u0026gt;\u0026gt; 1); // 如果扩容之后仍然不够,比如 oldCapacity=0,minCapacity=1 if (newCapacity - minCapacity \u0026lt; 0) // 直接采用minCapacity newCapacity = minCapacity; // 扩容之后比允许的最大容量都还大 if (newCapacity - MAX_ARRAY_SIZE \u0026gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 把原来的数据赋值过去 elementData = Arrays.copyOf(elementData, newCapacity); } 6.hugeCapacity 这个函数主要处理 minCapacity 太大的情况, 会在 newCapacity \u0026gt; MAX_ARRAY_SIZE 时使用\nprivate static int hugeCapacity(int minCapacity) { if (minCapacity \u0026lt; 0) // overflow throw new OutOfMemoryError(); // 如果所需的容量大于最大容量,则直接返回Integer.MAX_VALUE,否则返回最大容量 即Integer.MAX_VALUE-8 return (minCapacity \u0026gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; } 7.trimToSize 把数组的容量改为数组中元素的数量,减少内存占用\npublic void trimToSize() { modCount++; if (size \u0026lt; elementData.length) { elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); } } 迭代器 1.Itr 这个类中有一个expectedModCount属性,这个属性会在迭代器对象初始化的时候赋值,用于实现 fast-fail 机制,在每一次迭代的时候会判 断当前的 modCount 是否等于 expectedModCount, 如果不相等会抛出ConcurrentModificationException\nprivate class Itr implements Iterator\u0026lt;E\u0026gt; { int cursor; // index of next element to return int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; Itr() {} public boolean hasNext() { return cursor != size; } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E next() { checkForComodification(); int i = cursor; if (i \u0026gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; // 如果在迭代过程中发现i\u0026gt;= element.length,表明这个数组被其他线程修改了,抛出并发修改异常 if (i \u0026gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; } public void remove() { if (lastRet \u0026lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } @Override @SuppressWarnings(\u0026#34;Ïunchecked\u0026#34;) public void forEachRemaining(Consumer\u0026lt;? super E\u0026gt; consumer) { Objects.requireNonNull(consumer); final int size = ArrayList.this.size; int i = cursor; if (i \u0026gt;= size) { return; } final Object[] elementData = ArrayList.this.elementData; if (i \u0026gt;= elementData.length) { throw new ConcurrentModificationException(); } while (i != size \u0026amp;\u0026amp; modCount == expectedModCount) { consumer.accept((E) elementData[i++]); } // update once at end of iteration to reduce heap write traffic cursor = i; lastRet = i - 1; checkForComodification(); } final void checkForComodification() { // 保证当前modCount等于expectedModCount // 如果不相等 表明该数组被其他线程修改 if (modCount != expectedModCount) throw new ConcurrentModificationException(); } } 2.ListItr 这个类对Itr进行了一些扩展,新增了add和set方法,同时它还允许使用previous方法进行双向迭代\nprivate class ListItr extends Itr implements ListIterator\u0026lt;E\u0026gt; { ListItr(int index) { super(); cursor = index; } public boolean hasPrevious() { return cursor != 0; } public int nextIndex() { return cursor; } public int previousIndex() { return cursor - 1; } @SuppressWarnings(\u0026#34;unchecked\u0026#34;) public E previous() { checkForComodification(); int i = cursor - 1; if (i \u0026lt; 0) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i \u0026gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i; return (E) elementData[lastRet = i]; } public void set(E e) { if (lastRet \u0026lt; 0) throw new IllegalStateException(); checkForComodification(); try { ArrayList.this.set(lastRet, e); } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } public void add(E e) { checkForComodification(); try { int i = cursor; ArrayList.this.add(i, e); cursor = i + 1; lastRet = -1; expectedModCount = modCount; } catch (IndexOutOfBoundsException ex) { throw new ConcurrentModificationException(); } } } ","date":"2021-07-28T00:00:00Z","image":"https://howieyoung.oss-cn-chengdu.aliyuncs.com/blog/img/arraylist.png","permalink":"https://yanghaoyu.xyz/b/arraylist-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/","title":"ArrayList 源码阅读"},{"content":"回收哪些空间? JVM 要求回收堆,方法区中的垃圾\n在堆中回收没有指针指向的对象\n对于方法区, JVM 确实说过可以不要求虚拟机在永久代实现垃圾收集, 对于永久代的回收主要是回收废弃常量和无用的类\n废弃常量 在字符串常量池中存在 \u0026quot;abc\u0026quot;,但是没有任何指针指向这个字面量,那么这个\u0026quot;abc\u0026quot;就是废弃常量,在 gc 时会被清理\n无用的类\n该类所以实例已被回收 这个类的类对象没有被引用 该类的 ClassLoader 已被回收 如果某个满足上述上条件, 则这个类判定为无用的类, 可以被回收(不是一定被回收) 可以使用 -Xnoclassgc这个虚拟机选项 进行控制\n自从方法区的实现由永久代变为元空间, 方法区的溢出的情况大大减少\n如何判断哪些对象需要被回收? 1. 引用计数算法 给对象添加一个引用计数器,如果被指针引用起来,则计数器+1,当指针不在引用该对象时,计数器-1,当计数器==0,则释放该对象\n引用计数法的实现简单,效率高,但是 JVM 并未使用该算法,主要原因是这种算法很难解决循环引用的问题\n如下图, a 引用了 b,b 也引用了 a,但是没有其他指向 a 的指针,也没有其他指向 b 的指针,这两个对象都是无法使用的,理应删除,但是由于计数器不为 0,这两个对象依旧不会被释放 2.可达性分析 这种算法就是把所有对象构成一张图,对该图进行遍历,判断结点是否可达,如果可达,表明该对象有可能被使用,则不释放,如果不可达,则释放该对象\nJVM 规定从 GC Root 开始遍历,GC Root 主要包括以下几种对象:\n虚拟机栈(栈帧的本地变量表)中引用的对象 方法区(永久代/元空间)中静态属性引用的对象 方法区(永久代/元空间)中常量引用的对象 本地方法栈 JNI 引用到的对象 (native 方法引用的对象) 怎样回收对象? 1. 标记清除算法 (Mark-And-Sweep) 这个算法分为两个阶段 标记阶段: 首先把需要回收的对象标记出来 清除阶段: 对带标记的对象进行清理\n这种算法会产生大量的内存碎片,使得内存利用率降低,造成在生成新对象时查找下一个空闲块花费大量时间,效率降低\n2. 复制算法 (Copying) 这种算法解决了标记清除算法产生内存碎片的问题,它把内存分成 2 块,每次使用其中一块,每次进行清理时,把存活的对象复制到另一块,再把当前使用的块一次性全部清理\n这种算法的弊端主要在于可使用的内存降低了 50%,并且对于大对象的复制是非常耗时的,效率降低\n3.标记整理算法 (Mark-And-Compact) 这种算法主要思想为:在清理阶段需要把存活的对象全部向一端移动,然后直接回收掉边界以外的内存\n4. 分代收集算法 (Generation Collection) 这种算法综合使用了以上几种算法, 是主流的 GC 算法\nJVM 把堆区划分为两个年代,根据年代的不同而采用不同的算法\n新生代 (Young Gen) 这个区域对象存活率较低,大批对象死亡,采用复制算法清理这个区域的对象,占 1/3 老年代(Old Gen) 这个区域对象存活率高,采用标记整理算法,占 2/3 JVM 在新生代使用复制算法,它把新生代分为两块\n伊甸园(Eden) 占新生代 8/10 幸存者(Survivor) 占新生代 2/10 其中幸存者又被分为两块\nFrom 占幸存者 1/2 To 占幸存者 1/2 当 Eden 区满时,会除法 Minor GC,对新生代使用复制算法,把 Eden 和目前正在使用的 Survivor 区的垃圾进行标记,然后把可达的对象复制到另一个 Survivor 区域,并回收垃圾。随着新对象的生产，Eden 再次满时会使用相同的算法，对象会在 From 和 To 之间来回移动，如果这个移动超过 15 次(可以通过-XX:MaxTenuringThreshold 设置)，该对象会被放进老年代。\nJVM 存在内存担保机制,即大对象直接进入老年代,不会经过新生代\n当老年代的对象越来越多,直到老年代内存放不下了,会触发 Full GC 对新生代、老生代、方法区进行回收\n","date":"2021-06-03T00:00:00Z","permalink":"https://yanghaoyu.xyz/b/jvm-gc%E7%AE%97%E6%B3%95/","title":"JVM - GC算法"},{"content":" 单例模式的实现 饿汉式 class EagerSingleton { private static final EagerSingleton instance = new EagerSingleton(); private EagerSingleton() { } public static EagerSingleton getInstance() { return instance; } } 懒汉式 class LazySingleton { private static LazySingleton instance = null; private LazySingleton() { } public static LazySingleton getInstance() { if (instance == null) { instance = new LazySingleton(); } return instance; } } 线程安全的懒汉式 class LazySingleton { private static volatile LazySingleton instance = null; private LazySingleton() { } public static LazySingleton getInstance() { // 双重检查锁机制 // 性能优化，因为synchronized只在初始化的需要用到，之后都不需要用了，因此在外层判断一下 if (instance == null) { // 类对象作为锁 synchronized (LazySingleton.class) { // 判断是否初始化 if (instance == null) { // 1. 分配内存 2. 创建对象 3. instance指针指向该内存 // 有些编译器会优化上述步骤，可能将2，3调换， // 那么此时如果有线程进行外层的判断，那么它拿到的将是一个未初始化完成的对象 // 因此需要在instance加上volatile禁止指令重排序 instance = new LazySingleton(); } } } // 返回对象 return instance; } } 静态内部类 利用 JVM 的类加载机制实现单例,SingletonHolder并不会在Singleton加载时而加载,静态内部类是在首次使用时加载的\npublic class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton() {} public static Singleton getUniqueInstance() { return SingletonHolder.INSTANCE; } } 枚举 这种是 《Effective java》所推荐的实现方式\n线程安全，并且反射、clone、反序列化都无法破解单例\npublic enum EnumSingleton { INSTANCE; } 防止单例被侵犯 1. 利用反射强行调用构造器 使用反射可以强行调用私有的构造器，因此我们需要在构造器中抛出异常，防止调用\n以懒汉式为例，LazySingleton 只允许实例化一次，实例化之后都不允许再次实例\npublic class LazySingleton { private static volatile LazySingleton instance = null; private LazySingleton() { if (instance != null) { throw new RuntimeException(\u0026#34;单例被侵犯!\u0026#34;); } synchronized (LazySingleton.class) { // 只允许创建一次 if (instance == null) { instance = this; } else { throw new RuntimeException(\u0026#34;单例被侵犯!\u0026#34;); } } } public static LazySingleton getInstance() { if (instance == null) { synchronized (LazySingleton.class) { if (instance == null) { instance = new LazySingleton(); } } } // 返回对象 return instance; } } 2. 反序列化破坏单例 添加 readResolve 方法，这个方法会在反序列化时被调用 声明所有字段为 transient public class LazySingleton implements Serializable { private static final long serialVersionUID = -6732787633209815604L; private static volatile transient LazySingleton instance = null; private LazySingleton() { if (instance != null) { throw new RuntimeException(\u0026#34;单例被侵犯!\u0026#34;); } synchronized (LazySingleton.class) { if (instance == null) { instance = this; } else { throw new RuntimeException(\u0026#34;单例被侵犯!\u0026#34;); } } } public static LazySingleton getInstance() { if (instance == null) { synchronized (LazySingleton.class) { if (instance == null) { instance = new LazySingleton(); } } } return instance; } // 直接返回实例 private Object readResolve() { return getInstance(); } } 3.clone 破坏单例 clone 方法是不会调用构造器的，JVM 会直接拷贝内存，类似于 C++ 中的 memcpy 函数\n单例类是不应该重写 clone 方法的，如果非要重写，也要返回存在的单例\npublic class LazySingleton implements Serializable， Cloneable { private static final long serialVersionUID = -6732787633209815604L; private static volatile LazySingleton instance = null; private LazySingleton() { if (instance != null) { throw new RuntimeException(\u0026#34;单例被侵犯!\u0026#34;); } synchronized (LazySingleton.class) { if (instance == null) { instance = this; } else { throw new RuntimeException(\u0026#34;单例被侵犯!\u0026#34;); } } } public static LazySingleton getInstance() { if (instance == null) { synchronized (LazySingleton.class) { if (instance == null) { instance = new LazySingleton(); } } } return instance; } private Object readResolve() { return getInstance(); } // 直接返回实例 @Override public Object clone() throws CloneNotSupportedException { return getInstance(); } } ","date":"2021-02-14T00:00:00Z","permalink":"https://yanghaoyu.xyz/b/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","title":"设计模式-单例模式"}]